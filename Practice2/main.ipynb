{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:33:41.078343Z",
     "end_time": "2023-04-08T13:33:42.690507Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:33:42.692510Z",
     "end_time": "2023-04-08T13:33:43.993775Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_model = LeNet5().to(device)\n",
    "optimizer = torch.optim.Adam(params=train_model.parameters(), lr=1e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=20, gamma=0.5)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:33:43.994776Z",
     "end_time": "2023-04-08T13:33:44.104234Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='MNIST',\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=train_transform,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=128,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:33:44.105840Z",
     "end_time": "2023-04-08T13:33:44.152283Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/300: 100%|██████████| 469/469 [00:07<00:00, 59.43batches/s, GPU_mem=0.0503G, loss=2.26] \n",
      "Epoch 1/300: 100%|██████████| 469/469 [00:04<00:00, 100.24batches/s, GPU_mem=0.0503G, loss=2.08]\n",
      "Epoch 2/300: 100%|██████████| 469/469 [00:04<00:00, 97.45batches/s, GPU_mem=0.0503G, loss=1.72] \n",
      "Epoch 3/300: 100%|██████████| 469/469 [00:04<00:00, 107.55batches/s, GPU_mem=0.0503G, loss=1.39]\n",
      "Epoch 4/300: 100%|██████████| 469/469 [00:04<00:00, 104.06batches/s, GPU_mem=0.0503G, loss=1.19]\n",
      "Epoch 5/300: 100%|██████████| 469/469 [00:05<00:00, 84.36batches/s, GPU_mem=0.0503G, loss=1.06] \n",
      "Epoch 6/300: 100%|██████████| 469/469 [00:05<00:00, 82.27batches/s, GPU_mem=0.0503G, loss=0.967] \n",
      "Epoch 7/300: 100%|██████████| 469/469 [00:05<00:00, 80.36batches/s, GPU_mem=0.0503G, loss=0.899] \n",
      "Epoch 8/300: 100%|██████████| 469/469 [00:05<00:00, 81.46batches/s, GPU_mem=0.0503G, loss=0.845] \n",
      "Epoch 9/300: 100%|██████████| 469/469 [00:05<00:00, 78.82batches/s, GPU_mem=0.0503G, loss=0.802] \n",
      "Epoch 10/300: 100%|██████████| 469/469 [00:06<00:00, 75.32batches/s, GPU_mem=0.0503G, loss=0.766] \n",
      "Epoch 11/300: 100%|██████████| 469/469 [00:05<00:00, 78.37batches/s, GPU_mem=0.0503G, loss=0.735] \n",
      "Epoch 12/300: 100%|██████████| 469/469 [00:05<00:00, 79.22batches/s, GPU_mem=0.0503G, loss=0.708] \n",
      "Epoch 13/300: 100%|██████████| 469/469 [00:05<00:00, 78.36batches/s, GPU_mem=0.0503G, loss=0.685] \n",
      "Epoch 14/300: 100%|██████████| 469/469 [00:06<00:00, 75.72batches/s, GPU_mem=0.0503G, loss=0.663] \n",
      "Epoch 15/300: 100%|██████████| 469/469 [00:06<00:00, 77.44batches/s, GPU_mem=0.0503G, loss=0.644] \n",
      "Epoch 16/300: 100%|██████████| 469/469 [00:06<00:00, 76.74batches/s, GPU_mem=0.0503G, loss=0.626] \n",
      "Epoch 17/300: 100%|██████████| 469/469 [00:06<00:00, 69.98batches/s, GPU_mem=0.0503G, loss=0.61]  \n",
      "Epoch 18/300: 100%|██████████| 469/469 [00:04<00:00, 100.55batches/s, GPU_mem=0.0503G, loss=0.595]\n",
      "Epoch 19/300: 100%|██████████| 469/469 [00:04<00:00, 104.83batches/s, GPU_mem=0.0503G, loss=0.581]\n",
      "Epoch 20/300: 100%|██████████| 469/469 [00:04<00:00, 109.56batches/s, GPU_mem=0.0503G, loss=0.567]\n",
      "Epoch 21/300: 100%|██████████| 469/469 [00:05<00:00, 81.38batches/s, GPU_mem=0.0503G, loss=0.555] \n",
      "Epoch 22/300: 100%|██████████| 469/469 [00:06<00:00, 74.49batches/s, GPU_mem=0.0503G, loss=0.544] \n",
      "Epoch 23/300: 100%|██████████| 469/469 [00:06<00:00, 75.45batches/s, GPU_mem=0.0503G, loss=0.533] \n",
      "Epoch 24/300: 100%|██████████| 469/469 [00:06<00:00, 77.14batches/s, GPU_mem=0.0503G, loss=0.523] \n",
      "Epoch 25/300: 100%|██████████| 469/469 [00:06<00:00, 75.32batches/s, GPU_mem=0.0503G, loss=0.513] \n",
      "Epoch 26/300: 100%|██████████| 469/469 [00:06<00:00, 74.67batches/s, GPU_mem=0.0503G, loss=0.504] \n",
      "Epoch 27/300: 100%|██████████| 469/469 [00:06<00:00, 73.71batches/s, GPU_mem=0.0503G, loss=0.495] \n",
      "Epoch 28/300: 100%|██████████| 469/469 [00:06<00:00, 75.99batches/s, GPU_mem=0.0503G, loss=0.487] \n",
      "Epoch 29/300: 100%|██████████| 469/469 [00:06<00:00, 76.80batches/s, GPU_mem=0.0503G, loss=0.478] \n",
      "Epoch 30/300: 100%|██████████| 469/469 [00:05<00:00, 78.55batches/s, GPU_mem=0.0503G, loss=0.471] \n",
      "Epoch 31/300: 100%|██████████| 469/469 [00:06<00:00, 72.68batches/s, GPU_mem=0.0503G, loss=0.462] \n",
      "Epoch 32/300: 100%|██████████| 469/469 [00:06<00:00, 75.65batches/s, GPU_mem=0.0503G, loss=0.455] \n",
      "Epoch 33/300: 100%|██████████| 469/469 [00:05<00:00, 80.23batches/s, GPU_mem=0.0503G, loss=0.448] \n",
      "Epoch 34/300: 100%|██████████| 469/469 [00:05<00:00, 78.83batches/s, GPU_mem=0.0503G, loss=0.441] \n",
      "Epoch 35/300: 100%|██████████| 469/469 [00:06<00:00, 72.35batches/s, GPU_mem=0.0503G, loss=0.434] \n",
      "Epoch 36/300: 100%|██████████| 469/469 [00:06<00:00, 70.65batches/s, GPU_mem=0.0503G, loss=0.428] \n",
      "Epoch 37/300: 100%|██████████| 469/469 [00:06<00:00, 76.35batches/s, GPU_mem=0.0503G, loss=0.421] \n",
      "Epoch 38/300: 100%|██████████| 469/469 [00:06<00:00, 75.16batches/s, GPU_mem=0.0503G, loss=0.414] \n",
      "Epoch 39/300: 100%|██████████| 469/469 [00:06<00:00, 75.31batches/s, GPU_mem=0.0503G, loss=0.408] \n",
      "Epoch 40/300: 100%|██████████| 469/469 [00:06<00:00, 75.30batches/s, GPU_mem=0.0503G, loss=0.403] \n",
      "Epoch 41/300: 100%|██████████| 469/469 [00:06<00:00, 76.05batches/s, GPU_mem=0.0503G, loss=0.397] \n",
      "Epoch 42/300: 100%|██████████| 469/469 [00:06<00:00, 76.07batches/s, GPU_mem=0.0503G, loss=0.391] \n",
      "Epoch 43/300: 100%|██████████| 469/469 [00:06<00:00, 75.05batches/s, GPU_mem=0.0503G, loss=0.385] \n",
      "Epoch 44/300: 100%|██████████| 469/469 [00:05<00:00, 78.29batches/s, GPU_mem=0.0503G, loss=0.38]  \n",
      "Epoch 45/300: 100%|██████████| 469/469 [00:06<00:00, 74.99batches/s, GPU_mem=0.0503G, loss=0.374] \n",
      "Epoch 46/300: 100%|██████████| 469/469 [00:05<00:00, 79.01batches/s, GPU_mem=0.0503G, loss=0.369] \n",
      "Epoch 47/300: 100%|██████████| 469/469 [00:05<00:00, 81.93batches/s, GPU_mem=0.0503G, loss=0.364] \n",
      "Epoch 48/300: 100%|██████████| 469/469 [00:06<00:00, 75.57batches/s, GPU_mem=0.0503G, loss=0.359] \n",
      "Epoch 49/300: 100%|██████████| 469/469 [00:06<00:00, 77.29batches/s, GPU_mem=0.0503G, loss=0.354] \n",
      "Epoch 50/300: 100%|██████████| 469/469 [00:06<00:00, 72.59batches/s, GPU_mem=0.0503G, loss=0.349] \n",
      "Epoch 51/300: 100%|██████████| 469/469 [00:06<00:00, 73.74batches/s, GPU_mem=0.0503G, loss=0.344] \n",
      "Epoch 52/300: 100%|██████████| 469/469 [00:06<00:00, 76.09batches/s, GPU_mem=0.0503G, loss=0.34]  \n",
      "Epoch 53/300: 100%|██████████| 469/469 [00:06<00:00, 73.07batches/s, GPU_mem=0.0503G, loss=0.336] \n",
      "Epoch 54/300: 100%|██████████| 469/469 [00:06<00:00, 74.85batches/s, GPU_mem=0.0503G, loss=0.331] \n",
      "Epoch 55/300: 100%|██████████| 469/469 [00:06<00:00, 75.99batches/s, GPU_mem=0.0503G, loss=0.327] \n",
      "Epoch 56/300: 100%|██████████| 469/469 [00:06<00:00, 76.56batches/s, GPU_mem=0.0503G, loss=0.322] \n",
      "Epoch 57/300: 100%|██████████| 469/469 [00:06<00:00, 75.96batches/s, GPU_mem=0.0503G, loss=0.318] \n",
      "Epoch 58/300: 100%|██████████| 469/469 [00:06<00:00, 74.35batches/s, GPU_mem=0.0503G, loss=0.314] \n",
      "Epoch 59/300: 100%|██████████| 469/469 [00:06<00:00, 73.98batches/s, GPU_mem=0.0503G, loss=0.31]  \n",
      "Epoch 60/300: 100%|██████████| 469/469 [00:06<00:00, 72.35batches/s, GPU_mem=0.0503G, loss=0.306] \n",
      "Epoch 61/300: 100%|██████████| 469/469 [00:04<00:00, 99.18batches/s, GPU_mem=0.0503G, loss=0.302] \n",
      "Epoch 62/300: 100%|██████████| 469/469 [00:05<00:00, 80.18batches/s, GPU_mem=0.0503G, loss=0.298] \n",
      "Epoch 63/300: 100%|██████████| 469/469 [00:06<00:00, 71.49batches/s, GPU_mem=0.0503G, loss=0.294] \n",
      "Epoch 64/300: 100%|██████████| 469/469 [00:06<00:00, 74.61batches/s, GPU_mem=0.0503G, loss=0.291] \n",
      "Epoch 65/300: 100%|██████████| 469/469 [00:06<00:00, 74.69batches/s, GPU_mem=0.0503G, loss=0.287] \n",
      "Epoch 66/300: 100%|██████████| 469/469 [00:06<00:00, 72.61batches/s, GPU_mem=0.0503G, loss=0.284] \n",
      "Epoch 67/300: 100%|██████████| 469/469 [00:06<00:00, 74.12batches/s, GPU_mem=0.0503G, loss=0.28]  \n",
      "Epoch 68/300: 100%|██████████| 469/469 [00:04<00:00, 104.90batches/s, GPU_mem=0.0503G, loss=0.277]\n",
      "Epoch 69/300: 100%|██████████| 469/469 [00:04<00:00, 105.59batches/s, GPU_mem=0.0503G, loss=0.274]\n",
      "Epoch 70/300: 100%|██████████| 469/469 [00:04<00:00, 103.56batches/s, GPU_mem=0.0503G, loss=0.27] \n",
      "Epoch 71/300: 100%|██████████| 469/469 [00:04<00:00, 107.95batches/s, GPU_mem=0.0503G, loss=0.267]\n",
      "Epoch 72/300: 100%|██████████| 469/469 [00:04<00:00, 98.84batches/s, GPU_mem=0.0503G, loss=0.264] \n",
      "Epoch 73/300: 100%|██████████| 469/469 [00:05<00:00, 78.47batches/s, GPU_mem=0.0503G, loss=0.261] \n",
      "Epoch 74/300: 100%|██████████| 469/469 [00:06<00:00, 73.90batches/s, GPU_mem=0.0503G, loss=0.258] \n",
      "Epoch 75/300: 100%|██████████| 469/469 [00:06<00:00, 70.92batches/s, GPU_mem=0.0503G, loss=0.255] \n",
      "Epoch 76/300: 100%|██████████| 469/469 [00:06<00:00, 72.61batches/s, GPU_mem=0.0503G, loss=0.252] \n",
      "Epoch 77/300: 100%|██████████| 469/469 [00:06<00:00, 73.80batches/s, GPU_mem=0.0503G, loss=0.25]  \n",
      "Epoch 78/300: 100%|██████████| 469/469 [00:04<00:00, 103.70batches/s, GPU_mem=0.0503G, loss=0.247]\n",
      "Epoch 79/300: 100%|██████████| 469/469 [00:04<00:00, 111.24batches/s, GPU_mem=0.0503G, loss=0.244]\n",
      "Epoch 80/300: 100%|██████████| 469/469 [00:06<00:00, 77.24batches/s, GPU_mem=0.0503G, loss=0.241] \n",
      "Epoch 81/300: 100%|██████████| 469/469 [00:06<00:00, 73.87batches/s, GPU_mem=0.0503G, loss=0.239] \n",
      "Epoch 82/300: 100%|██████████| 469/469 [00:06<00:00, 74.02batches/s, GPU_mem=0.0503G, loss=0.237] \n",
      "Epoch 83/300: 100%|██████████| 469/469 [00:06<00:00, 74.22batches/s, GPU_mem=0.0503G, loss=0.235] \n",
      "Epoch 84/300: 100%|██████████| 469/469 [00:06<00:00, 74.99batches/s, GPU_mem=0.0503G, loss=0.232] \n",
      "Epoch 85/300: 100%|██████████| 469/469 [00:06<00:00, 75.90batches/s, GPU_mem=0.0503G, loss=0.229] \n",
      "Epoch 86/300: 100%|██████████| 469/469 [00:06<00:00, 75.03batches/s, GPU_mem=0.0503G, loss=0.227] \n",
      "Epoch 87/300: 100%|██████████| 469/469 [00:04<00:00, 108.00batches/s, GPU_mem=0.0503G, loss=0.225]\n",
      "Epoch 88/300: 100%|██████████| 469/469 [00:04<00:00, 113.01batches/s, GPU_mem=0.0503G, loss=0.223]\n",
      "Epoch 89/300: 100%|██████████| 469/469 [00:04<00:00, 110.76batches/s, GPU_mem=0.0503G, loss=0.221]\n",
      "Epoch 90/300: 100%|██████████| 469/469 [00:04<00:00, 110.77batches/s, GPU_mem=0.0503G, loss=0.219]\n",
      "Epoch 91/300: 100%|██████████| 469/469 [00:04<00:00, 108.32batches/s, GPU_mem=0.0503G, loss=0.217]\n",
      "Epoch 92/300: 100%|██████████| 469/469 [00:04<00:00, 110.48batches/s, GPU_mem=0.0503G, loss=0.214]\n",
      "Epoch 93/300: 100%|██████████| 469/469 [00:04<00:00, 107.25batches/s, GPU_mem=0.0503G, loss=0.213]\n",
      "Epoch 94/300: 100%|██████████| 469/469 [00:04<00:00, 112.39batches/s, GPU_mem=0.0503G, loss=0.21] \n",
      "Epoch 95/300: 100%|██████████| 469/469 [00:04<00:00, 106.09batches/s, GPU_mem=0.0503G, loss=0.209]\n",
      "Epoch 96/300: 100%|██████████| 469/469 [00:04<00:00, 108.13batches/s, GPU_mem=0.0503G, loss=0.207]\n",
      "Epoch 97/300: 100%|██████████| 469/469 [00:04<00:00, 109.70batches/s, GPU_mem=0.0503G, loss=0.205]\n",
      "Epoch 98/300: 100%|██████████| 469/469 [00:04<00:00, 107.10batches/s, GPU_mem=0.0503G, loss=0.203]\n",
      "Epoch 99/300: 100%|██████████| 469/469 [00:04<00:00, 105.00batches/s, GPU_mem=0.0503G, loss=0.202]\n",
      "Epoch 100/300: 100%|██████████| 469/469 [00:04<00:00, 110.92batches/s, GPU_mem=0.0503G, loss=0.2]  \n",
      "Epoch 101/300: 100%|██████████| 469/469 [00:04<00:00, 111.73batches/s, GPU_mem=0.0503G, loss=0.198]\n",
      "Epoch 102/300: 100%|██████████| 469/469 [00:04<00:00, 108.53batches/s, GPU_mem=0.0503G, loss=0.196]\n",
      "Epoch 103/300: 100%|██████████| 469/469 [00:04<00:00, 105.29batches/s, GPU_mem=0.0503G, loss=0.195]\n",
      "Epoch 104/300: 100%|██████████| 469/469 [00:04<00:00, 108.27batches/s, GPU_mem=0.0503G, loss=0.193]\n",
      "Epoch 105/300: 100%|██████████| 469/469 [00:04<00:00, 109.14batches/s, GPU_mem=0.0503G, loss=0.192]\n",
      "Epoch 106/300: 100%|██████████| 469/469 [00:04<00:00, 109.57batches/s, GPU_mem=0.0503G, loss=0.19] \n",
      "Epoch 107/300: 100%|██████████| 469/469 [00:04<00:00, 106.95batches/s, GPU_mem=0.0503G, loss=0.188]\n",
      "Epoch 108/300: 100%|██████████| 469/469 [00:04<00:00, 112.05batches/s, GPU_mem=0.0503G, loss=0.187]\n",
      "Epoch 109/300: 100%|██████████| 469/469 [00:04<00:00, 106.07batches/s, GPU_mem=0.0503G, loss=0.185]\n",
      "Epoch 110/300: 100%|██████████| 469/469 [00:04<00:00, 111.23batches/s, GPU_mem=0.0503G, loss=0.184]\n",
      "Epoch 111/300: 100%|██████████| 469/469 [00:04<00:00, 110.23batches/s, GPU_mem=0.0503G, loss=0.183]\n",
      "Epoch 112/300: 100%|██████████| 469/469 [00:04<00:00, 109.41batches/s, GPU_mem=0.0503G, loss=0.181]\n",
      "Epoch 113/300: 100%|██████████| 469/469 [00:04<00:00, 106.05batches/s, GPU_mem=0.0503G, loss=0.18] \n",
      "Epoch 114/300: 100%|██████████| 469/469 [00:04<00:00, 106.77batches/s, GPU_mem=0.0503G, loss=0.178]\n",
      "Epoch 115/300: 100%|██████████| 469/469 [00:04<00:00, 111.12batches/s, GPU_mem=0.0503G, loss=0.177]\n",
      "Epoch 116/300: 100%|██████████| 469/469 [00:04<00:00, 111.25batches/s, GPU_mem=0.0503G, loss=0.176]\n",
      "Epoch 117/300: 100%|██████████| 469/469 [00:04<00:00, 113.18batches/s, GPU_mem=0.0503G, loss=0.174]\n",
      "Epoch 118/300: 100%|██████████| 469/469 [00:04<00:00, 112.45batches/s, GPU_mem=0.0503G, loss=0.173]\n",
      "Epoch 119/300: 100%|██████████| 469/469 [00:04<00:00, 110.51batches/s, GPU_mem=0.0503G, loss=0.171]\n",
      "Epoch 120/300: 100%|██████████| 469/469 [00:04<00:00, 106.34batches/s, GPU_mem=0.0503G, loss=0.171]\n",
      "Epoch 121/300: 100%|██████████| 469/469 [00:04<00:00, 107.48batches/s, GPU_mem=0.0503G, loss=0.169]\n",
      "Epoch 122/300: 100%|██████████| 469/469 [00:04<00:00, 113.54batches/s, GPU_mem=0.0503G, loss=0.168]\n",
      "Epoch 123/300: 100%|██████████| 469/469 [00:04<00:00, 111.22batches/s, GPU_mem=0.0503G, loss=0.167]\n",
      "Epoch 124/300: 100%|██████████| 469/469 [00:04<00:00, 108.22batches/s, GPU_mem=0.0503G, loss=0.165]\n",
      "Epoch 125/300: 100%|██████████| 469/469 [00:04<00:00, 113.08batches/s, GPU_mem=0.0503G, loss=0.164]\n",
      "Epoch 126/300: 100%|██████████| 469/469 [00:04<00:00, 111.63batches/s, GPU_mem=0.0503G, loss=0.163]\n",
      "Epoch 127/300: 100%|██████████| 469/469 [00:04<00:00, 110.52batches/s, GPU_mem=0.0503G, loss=0.162]\n",
      "Epoch 128/300: 100%|██████████| 469/469 [00:04<00:00, 111.66batches/s, GPU_mem=0.0503G, loss=0.161]\n",
      "Epoch 129/300: 100%|██████████| 469/469 [00:04<00:00, 110.65batches/s, GPU_mem=0.0503G, loss=0.16] \n",
      "Epoch 130/300: 100%|██████████| 469/469 [00:04<00:00, 110.05batches/s, GPU_mem=0.0503G, loss=0.159]\n",
      "Epoch 131/300: 100%|██████████| 469/469 [00:04<00:00, 108.01batches/s, GPU_mem=0.0503G, loss=0.158]\n",
      "Epoch 132/300: 100%|██████████| 469/469 [00:04<00:00, 107.82batches/s, GPU_mem=0.0503G, loss=0.157]\n",
      "Epoch 133/300: 100%|██████████| 469/469 [00:04<00:00, 104.51batches/s, GPU_mem=0.0503G, loss=0.156]\n",
      "Epoch 134/300: 100%|██████████| 469/469 [00:04<00:00, 102.84batches/s, GPU_mem=0.0503G, loss=0.155]\n",
      "Epoch 135/300: 100%|██████████| 469/469 [00:04<00:00, 114.75batches/s, GPU_mem=0.0503G, loss=0.153]\n",
      "Epoch 136/300: 100%|██████████| 469/469 [00:04<00:00, 107.88batches/s, GPU_mem=0.0503G, loss=0.152]\n",
      "Epoch 137/300: 100%|██████████| 469/469 [00:04<00:00, 107.03batches/s, GPU_mem=0.0503G, loss=0.152]\n",
      "Epoch 138/300: 100%|██████████| 469/469 [00:04<00:00, 112.71batches/s, GPU_mem=0.0503G, loss=0.151]\n",
      "Epoch 139/300: 100%|██████████| 469/469 [00:04<00:00, 113.92batches/s, GPU_mem=0.0503G, loss=0.151]\n",
      "Epoch 140/300: 100%|██████████| 469/469 [00:04<00:00, 110.22batches/s, GPU_mem=0.0503G, loss=0.149]\n",
      "Epoch 141/300: 100%|██████████| 469/469 [00:04<00:00, 108.99batches/s, GPU_mem=0.0503G, loss=0.148]\n",
      "Epoch 142/300: 100%|██████████| 469/469 [00:04<00:00, 112.05batches/s, GPU_mem=0.0503G, loss=0.147]\n",
      "Epoch 143/300: 100%|██████████| 469/469 [00:04<00:00, 108.20batches/s, GPU_mem=0.0503G, loss=0.146]\n",
      "Epoch 144/300: 100%|██████████| 469/469 [00:04<00:00, 109.72batches/s, GPU_mem=0.0503G, loss=0.145]\n",
      "Epoch 145/300: 100%|██████████| 469/469 [00:04<00:00, 110.36batches/s, GPU_mem=0.0503G, loss=0.144]\n",
      "Epoch 146/300: 100%|██████████| 469/469 [00:04<00:00, 107.10batches/s, GPU_mem=0.0503G, loss=0.143]\n",
      "Epoch 147/300: 100%|██████████| 469/469 [00:04<00:00, 109.63batches/s, GPU_mem=0.0503G, loss=0.143]\n",
      "Epoch 148/300: 100%|██████████| 469/469 [00:04<00:00, 105.97batches/s, GPU_mem=0.0503G, loss=0.142]\n",
      "Epoch 149/300: 100%|██████████| 469/469 [00:05<00:00, 92.74batches/s, GPU_mem=0.0503G, loss=0.141] \n",
      "Epoch 150/300: 100%|██████████| 469/469 [00:04<00:00, 102.28batches/s, GPU_mem=0.0503G, loss=0.14] \n",
      "Epoch 151/300: 100%|██████████| 469/469 [00:04<00:00, 94.74batches/s, GPU_mem=0.0503G, loss=0.14]  \n",
      "Epoch 152/300: 100%|██████████| 469/469 [00:04<00:00, 99.74batches/s, GPU_mem=0.0503G, loss=0.139] \n",
      "Epoch 153/300: 100%|██████████| 469/469 [00:04<00:00, 98.70batches/s, GPU_mem=0.0503G, loss=0.138] \n",
      "Epoch 154/300: 100%|██████████| 469/469 [00:04<00:00, 107.17batches/s, GPU_mem=0.0503G, loss=0.137]\n",
      "Epoch 155/300: 100%|██████████| 469/469 [00:04<00:00, 102.69batches/s, GPU_mem=0.0503G, loss=0.136]\n",
      "Epoch 156/300: 100%|██████████| 469/469 [00:04<00:00, 106.26batches/s, GPU_mem=0.0503G, loss=0.136]\n",
      "Epoch 157/300: 100%|██████████| 469/469 [00:04<00:00, 105.64batches/s, GPU_mem=0.0503G, loss=0.135]\n",
      "Epoch 158/300: 100%|██████████| 469/469 [00:04<00:00, 110.15batches/s, GPU_mem=0.0503G, loss=0.134]\n",
      "Epoch 159/300: 100%|██████████| 469/469 [00:04<00:00, 110.43batches/s, GPU_mem=0.0503G, loss=0.133]\n",
      "Epoch 160/300: 100%|██████████| 469/469 [00:04<00:00, 104.04batches/s, GPU_mem=0.0503G, loss=0.133]\n",
      "Epoch 161/300: 100%|██████████| 469/469 [00:04<00:00, 104.20batches/s, GPU_mem=0.0503G, loss=0.132]\n",
      "Epoch 162/300: 100%|██████████| 469/469 [00:04<00:00, 111.11batches/s, GPU_mem=0.0503G, loss=0.132]\n",
      "Epoch 163/300: 100%|██████████| 469/469 [00:04<00:00, 105.59batches/s, GPU_mem=0.0503G, loss=0.132]\n",
      "Epoch 164/300: 100%|██████████| 469/469 [00:04<00:00, 103.82batches/s, GPU_mem=0.0503G, loss=0.13] \n",
      "Epoch 165/300: 100%|██████████| 469/469 [00:04<00:00, 105.70batches/s, GPU_mem=0.0503G, loss=0.129]\n",
      "Epoch 166/300: 100%|██████████| 469/469 [00:04<00:00, 107.63batches/s, GPU_mem=0.0503G, loss=0.129]\n",
      "Epoch 167/300: 100%|██████████| 469/469 [00:04<00:00, 114.49batches/s, GPU_mem=0.0503G, loss=0.128]\n",
      "Epoch 168/300: 100%|██████████| 469/469 [00:04<00:00, 113.91batches/s, GPU_mem=0.0503G, loss=0.127]\n",
      "Epoch 169/300: 100%|██████████| 469/469 [00:04<00:00, 112.78batches/s, GPU_mem=0.0503G, loss=0.127]\n",
      "Epoch 170/300: 100%|██████████| 469/469 [00:04<00:00, 107.18batches/s, GPU_mem=0.0503G, loss=0.127]\n",
      "Epoch 171/300: 100%|██████████| 469/469 [00:04<00:00, 102.27batches/s, GPU_mem=0.0503G, loss=0.125]\n",
      "Epoch 172/300: 100%|██████████| 469/469 [00:05<00:00, 90.03batches/s, GPU_mem=0.0503G, loss=0.125] \n",
      "Epoch 173/300: 100%|██████████| 469/469 [00:04<00:00, 103.17batches/s, GPU_mem=0.0503G, loss=0.124]\n",
      "Epoch 174/300: 100%|██████████| 469/469 [00:04<00:00, 106.57batches/s, GPU_mem=0.0503G, loss=0.123]\n",
      "Epoch 175/300: 100%|██████████| 469/469 [00:04<00:00, 103.79batches/s, GPU_mem=0.0503G, loss=0.124]\n",
      "Epoch 176/300: 100%|██████████| 469/469 [00:04<00:00, 104.96batches/s, GPU_mem=0.0503G, loss=0.122]\n",
      "Epoch 177/300: 100%|██████████| 469/469 [00:04<00:00, 108.36batches/s, GPU_mem=0.0503G, loss=0.122]\n",
      "Epoch 178/300: 100%|██████████| 469/469 [00:04<00:00, 111.93batches/s, GPU_mem=0.0503G, loss=0.122]\n",
      "Epoch 179/300: 100%|██████████| 469/469 [00:04<00:00, 112.30batches/s, GPU_mem=0.0503G, loss=0.121]\n",
      "Epoch 180/300: 100%|██████████| 469/469 [00:04<00:00, 105.35batches/s, GPU_mem=0.0503G, loss=0.12] \n",
      "Epoch 181/300: 100%|██████████| 469/469 [00:04<00:00, 108.83batches/s, GPU_mem=0.0503G, loss=0.12] \n",
      "Epoch 182/300: 100%|██████████| 469/469 [00:04<00:00, 112.00batches/s, GPU_mem=0.0503G, loss=0.119]\n",
      "Epoch 183/300: 100%|██████████| 469/469 [00:04<00:00, 108.51batches/s, GPU_mem=0.0503G, loss=0.118]\n",
      "Epoch 184/300: 100%|██████████| 469/469 [00:04<00:00, 105.18batches/s, GPU_mem=0.0503G, loss=0.118]\n",
      "Epoch 185/300: 100%|██████████| 469/469 [00:04<00:00, 99.76batches/s, GPU_mem=0.0503G, loss=0.118] \n",
      "Epoch 186/300: 100%|██████████| 469/469 [00:04<00:00, 104.05batches/s, GPU_mem=0.0503G, loss=0.117]\n",
      "Epoch 187/300: 100%|██████████| 469/469 [00:04<00:00, 104.85batches/s, GPU_mem=0.0503G, loss=0.116]\n",
      "Epoch 188/300: 100%|██████████| 469/469 [00:04<00:00, 106.02batches/s, GPU_mem=0.0503G, loss=0.116]\n",
      "Epoch 189/300: 100%|██████████| 469/469 [00:04<00:00, 103.99batches/s, GPU_mem=0.0503G, loss=0.115]\n",
      "Epoch 190/300: 100%|██████████| 469/469 [00:04<00:00, 108.61batches/s, GPU_mem=0.0503G, loss=0.115]\n",
      "Epoch 191/300: 100%|██████████| 469/469 [00:04<00:00, 109.49batches/s, GPU_mem=0.0503G, loss=0.114]\n",
      "Epoch 192/300: 100%|██████████| 469/469 [00:04<00:00, 104.85batches/s, GPU_mem=0.0503G, loss=0.114]\n",
      "Epoch 193/300: 100%|██████████| 469/469 [00:04<00:00, 103.86batches/s, GPU_mem=0.0503G, loss=0.113]\n",
      "Epoch 194/300: 100%|██████████| 469/469 [00:04<00:00, 105.43batches/s, GPU_mem=0.0503G, loss=0.113]\n",
      "Epoch 195/300: 100%|██████████| 469/469 [00:04<00:00, 108.67batches/s, GPU_mem=0.0503G, loss=0.112]\n",
      "Epoch 196/300: 100%|██████████| 469/469 [00:04<00:00, 107.88batches/s, GPU_mem=0.0503G, loss=0.112]\n",
      "Epoch 197/300: 100%|██████████| 469/469 [00:04<00:00, 106.19batches/s, GPU_mem=0.0503G, loss=0.11] \n",
      "Epoch 198/300: 100%|██████████| 469/469 [00:04<00:00, 105.42batches/s, GPU_mem=0.0503G, loss=0.11] \n",
      "Epoch 199/300: 100%|██████████| 469/469 [00:04<00:00, 104.75batches/s, GPU_mem=0.0503G, loss=0.11] \n",
      "Epoch 200/300: 100%|██████████| 469/469 [00:04<00:00, 101.17batches/s, GPU_mem=0.0503G, loss=0.109]\n",
      "Epoch 201/300: 100%|██████████| 469/469 [00:04<00:00, 102.32batches/s, GPU_mem=0.0503G, loss=0.109]\n",
      "Epoch 202/300: 100%|██████████| 469/469 [00:04<00:00, 104.34batches/s, GPU_mem=0.0503G, loss=0.109]\n",
      "Epoch 203/300: 100%|██████████| 469/469 [00:04<00:00, 101.76batches/s, GPU_mem=0.0503G, loss=0.108]\n",
      "Epoch 204/300: 100%|██████████| 469/469 [00:04<00:00, 107.80batches/s, GPU_mem=0.0503G, loss=0.108]\n",
      "Epoch 205/300: 100%|██████████| 469/469 [00:04<00:00, 108.32batches/s, GPU_mem=0.0503G, loss=0.107]\n",
      "Epoch 206/300: 100%|██████████| 469/469 [00:04<00:00, 103.73batches/s, GPU_mem=0.0503G, loss=0.107]\n",
      "Epoch 207/300: 100%|██████████| 469/469 [00:04<00:00, 102.16batches/s, GPU_mem=0.0503G, loss=0.106]\n",
      "Epoch 208/300: 100%|██████████| 469/469 [00:05<00:00, 93.17batches/s, GPU_mem=0.0503G, loss=0.106] \n",
      "Epoch 209/300: 100%|██████████| 469/469 [00:04<00:00, 99.87batches/s, GPU_mem=0.0503G, loss=0.105] \n",
      "Epoch 210/300: 100%|██████████| 469/469 [00:04<00:00, 103.70batches/s, GPU_mem=0.0503G, loss=0.105]\n",
      "Epoch 211/300: 100%|██████████| 469/469 [00:04<00:00, 98.04batches/s, GPU_mem=0.0503G, loss=0.104] \n",
      "Epoch 212/300: 100%|██████████| 469/469 [00:04<00:00, 109.83batches/s, GPU_mem=0.0503G, loss=0.104]\n",
      "Epoch 213/300: 100%|██████████| 469/469 [00:04<00:00, 110.29batches/s, GPU_mem=0.0503G, loss=0.104]\n",
      "Epoch 214/300: 100%|██████████| 469/469 [00:04<00:00, 106.31batches/s, GPU_mem=0.0503G, loss=0.104]\n",
      "Epoch 215/300: 100%|██████████| 469/469 [00:04<00:00, 102.69batches/s, GPU_mem=0.0503G, loss=0.104]\n",
      "Epoch 216/300: 100%|██████████| 469/469 [00:04<00:00, 103.68batches/s, GPU_mem=0.0503G, loss=0.102]\n",
      "Epoch 217/300: 100%|██████████| 469/469 [00:04<00:00, 111.01batches/s, GPU_mem=0.0503G, loss=0.102] \n",
      "Epoch 218/300: 100%|██████████| 469/469 [00:04<00:00, 96.28batches/s, GPU_mem=0.0503G, loss=0.102]  \n",
      "Epoch 219/300: 100%|██████████| 469/469 [00:04<00:00, 108.71batches/s, GPU_mem=0.0503G, loss=0.102] \n",
      "Epoch 220/300: 100%|██████████| 469/469 [00:04<00:00, 107.06batches/s, GPU_mem=0.0503G, loss=0.1]   \n",
      "Epoch 221/300: 100%|██████████| 469/469 [00:04<00:00, 108.44batches/s, GPU_mem=0.0503G, loss=0.101] \n",
      "Epoch 222/300: 100%|██████████| 469/469 [00:05<00:00, 93.61batches/s, GPU_mem=0.0503G, loss=0.101]  \n",
      "Epoch 223/300: 100%|██████████| 469/469 [00:04<00:00, 98.53batches/s, GPU_mem=0.0503G, loss=0.0998] \n",
      "Epoch 224/300: 100%|██████████| 469/469 [00:04<00:00, 102.98batches/s, GPU_mem=0.0503G, loss=0.0992]\n",
      "Epoch 225/300: 100%|██████████| 469/469 [00:04<00:00, 98.18batches/s, GPU_mem=0.0503G, loss=0.0991] \n",
      "Epoch 226/300: 100%|██████████| 469/469 [00:04<00:00, 106.17batches/s, GPU_mem=0.0503G, loss=0.098] \n",
      "Epoch 227/300: 100%|██████████| 469/469 [00:04<00:00, 112.21batches/s, GPU_mem=0.0503G, loss=0.0982]\n",
      "Epoch 228/300: 100%|██████████| 469/469 [00:04<00:00, 109.57batches/s, GPU_mem=0.0503G, loss=0.0977]\n",
      "Epoch 229/300: 100%|██████████| 469/469 [00:04<00:00, 111.10batches/s, GPU_mem=0.0503G, loss=0.0974]\n",
      "Epoch 230/300: 100%|██████████| 469/469 [00:04<00:00, 102.89batches/s, GPU_mem=0.0503G, loss=0.0961]\n",
      "Epoch 231/300: 100%|██████████| 469/469 [00:04<00:00, 111.09batches/s, GPU_mem=0.0503G, loss=0.0967]\n",
      "Epoch 232/300: 100%|██████████| 469/469 [00:04<00:00, 101.07batches/s, GPU_mem=0.0503G, loss=0.0964]\n",
      "Epoch 233/300: 100%|██████████| 469/469 [00:04<00:00, 107.19batches/s, GPU_mem=0.0503G, loss=0.096] \n",
      "Epoch 234/300: 100%|██████████| 469/469 [00:04<00:00, 109.82batches/s, GPU_mem=0.0503G, loss=0.0954]\n",
      "Epoch 235/300: 100%|██████████| 469/469 [00:04<00:00, 113.74batches/s, GPU_mem=0.0503G, loss=0.0951]\n",
      "Epoch 236/300: 100%|██████████| 469/469 [00:04<00:00, 108.00batches/s, GPU_mem=0.0503G, loss=0.0951]\n",
      "Epoch 237/300: 100%|██████████| 469/469 [00:04<00:00, 102.59batches/s, GPU_mem=0.0503G, loss=0.0943]\n",
      "Epoch 238/300: 100%|██████████| 469/469 [00:04<00:00, 101.05batches/s, GPU_mem=0.0503G, loss=0.0941]\n",
      "Epoch 239/300: 100%|██████████| 469/469 [00:04<00:00, 96.76batches/s, GPU_mem=0.0503G, loss=0.0931] \n",
      "Epoch 240/300: 100%|██████████| 469/469 [00:04<00:00, 109.86batches/s, GPU_mem=0.0503G, loss=0.0931]\n",
      "Epoch 241/300: 100%|██████████| 469/469 [00:04<00:00, 102.61batches/s, GPU_mem=0.0503G, loss=0.0929]\n",
      "Epoch 242/300: 100%|██████████| 469/469 [00:04<00:00, 106.06batches/s, GPU_mem=0.0503G, loss=0.0925]\n",
      "Epoch 243/300: 100%|██████████| 469/469 [00:04<00:00, 109.82batches/s, GPU_mem=0.0503G, loss=0.0921]\n",
      "Epoch 244/300: 100%|██████████| 469/469 [00:04<00:00, 108.05batches/s, GPU_mem=0.0503G, loss=0.092] \n",
      "Epoch 245/300: 100%|██████████| 469/469 [00:04<00:00, 109.80batches/s, GPU_mem=0.0503G, loss=0.0914]\n",
      "Epoch 246/300: 100%|██████████| 469/469 [00:04<00:00, 110.74batches/s, GPU_mem=0.0503G, loss=0.0919]\n",
      "Epoch 247/300: 100%|██████████| 469/469 [00:04<00:00, 110.68batches/s, GPU_mem=0.0503G, loss=0.0909]\n",
      "Epoch 248/300: 100%|██████████| 469/469 [00:04<00:00, 108.62batches/s, GPU_mem=0.0503G, loss=0.0909]\n",
      "Epoch 249/300: 100%|██████████| 469/469 [00:04<00:00, 103.49batches/s, GPU_mem=0.0503G, loss=0.0905]\n",
      "Epoch 250/300: 100%|██████████| 469/469 [00:04<00:00, 107.01batches/s, GPU_mem=0.0503G, loss=0.09]  \n",
      "Epoch 251/300: 100%|██████████| 469/469 [00:04<00:00, 104.83batches/s, GPU_mem=0.0503G, loss=0.0898]\n",
      "Epoch 252/300: 100%|██████████| 469/469 [00:04<00:00, 104.70batches/s, GPU_mem=0.0503G, loss=0.0891]\n",
      "Epoch 253/300: 100%|██████████| 469/469 [00:04<00:00, 102.47batches/s, GPU_mem=0.0503G, loss=0.0892]\n",
      "Epoch 254/300: 100%|██████████| 469/469 [00:04<00:00, 104.22batches/s, GPU_mem=0.0503G, loss=0.0884]\n",
      "Epoch 255/300: 100%|██████████| 469/469 [00:06<00:00, 74.83batches/s, GPU_mem=0.0503G, loss=0.0888] \n",
      "Epoch 256/300: 100%|██████████| 469/469 [00:06<00:00, 75.11batches/s, GPU_mem=0.0503G, loss=0.0876] \n",
      "Epoch 257/300: 100%|██████████| 469/469 [00:06<00:00, 72.88batches/s, GPU_mem=0.0503G, loss=0.0872] \n",
      "Epoch 258/300: 100%|██████████| 469/469 [00:06<00:00, 75.51batches/s, GPU_mem=0.0503G, loss=0.0869] \n",
      "Epoch 259/300: 100%|██████████| 469/469 [00:05<00:00, 78.18batches/s, GPU_mem=0.0503G, loss=0.0868] \n",
      "Epoch 260/300: 100%|██████████| 469/469 [00:06<00:00, 75.41batches/s, GPU_mem=0.0503G, loss=0.0868] \n",
      "Epoch 261/300: 100%|██████████| 469/469 [00:06<00:00, 77.20batches/s, GPU_mem=0.0503G, loss=0.0862] \n",
      "Epoch 262/300: 100%|██████████| 469/469 [00:06<00:00, 77.63batches/s, GPU_mem=0.0503G, loss=0.0861] \n",
      "Epoch 263/300: 100%|██████████| 469/469 [00:05<00:00, 78.91batches/s, GPU_mem=0.0503G, loss=0.0859] \n",
      "Epoch 264/300: 100%|██████████| 469/469 [00:05<00:00, 79.56batches/s, GPU_mem=0.0503G, loss=0.0857] \n",
      "Epoch 265/300: 100%|██████████| 469/469 [00:05<00:00, 78.98batches/s, GPU_mem=0.0503G, loss=0.0848] \n",
      "Epoch 266/300: 100%|██████████| 469/469 [00:05<00:00, 78.65batches/s, GPU_mem=0.0503G, loss=0.0847] \n",
      "Epoch 267/300: 100%|██████████| 469/469 [00:06<00:00, 77.91batches/s, GPU_mem=0.0503G, loss=0.0844] \n",
      "Epoch 268/300: 100%|██████████| 469/469 [00:06<00:00, 77.31batches/s, GPU_mem=0.0503G, loss=0.0848] \n",
      "Epoch 269/300: 100%|██████████| 469/469 [00:05<00:00, 79.09batches/s, GPU_mem=0.0503G, loss=0.0842] \n",
      "Epoch 270/300: 100%|██████████| 469/469 [00:06<00:00, 77.02batches/s, GPU_mem=0.0503G, loss=0.0836] \n",
      "Epoch 271/300: 100%|██████████| 469/469 [00:05<00:00, 80.18batches/s, GPU_mem=0.0503G, loss=0.0834] \n",
      "Epoch 272/300: 100%|██████████| 469/469 [00:06<00:00, 77.73batches/s, GPU_mem=0.0503G, loss=0.0833] \n",
      "Epoch 273/300: 100%|██████████| 469/469 [00:06<00:00, 76.25batches/s, GPU_mem=0.0503G, loss=0.0828] \n",
      "Epoch 274/300: 100%|██████████| 469/469 [00:05<00:00, 78.42batches/s, GPU_mem=0.0503G, loss=0.0821] \n",
      "Epoch 275/300: 100%|██████████| 469/469 [00:06<00:00, 76.86batches/s, GPU_mem=0.0503G, loss=0.0823] \n",
      "Epoch 276/300: 100%|██████████| 469/469 [00:06<00:00, 76.99batches/s, GPU_mem=0.0503G, loss=0.0819] \n",
      "Epoch 277/300: 100%|██████████| 469/469 [00:05<00:00, 79.66batches/s, GPU_mem=0.0503G, loss=0.0814] \n",
      "Epoch 278/300: 100%|██████████| 469/469 [00:06<00:00, 75.68batches/s, GPU_mem=0.0503G, loss=0.0813] \n",
      "Epoch 279/300: 100%|██████████| 469/469 [00:06<00:00, 77.18batches/s, GPU_mem=0.0503G, loss=0.0808] \n",
      "Epoch 280/300: 100%|██████████| 469/469 [00:06<00:00, 78.01batches/s, GPU_mem=0.0503G, loss=0.0803] \n",
      "Epoch 281/300: 100%|██████████| 469/469 [00:05<00:00, 78.63batches/s, GPU_mem=0.0503G, loss=0.0809] \n",
      "Epoch 282/300: 100%|██████████| 469/469 [00:05<00:00, 78.37batches/s, GPU_mem=0.0503G, loss=0.0803] \n",
      "Epoch 283/300: 100%|██████████| 469/469 [00:06<00:00, 77.90batches/s, GPU_mem=0.0503G, loss=0.0803] \n",
      "Epoch 284/300: 100%|██████████| 469/469 [00:06<00:00, 75.28batches/s, GPU_mem=0.0503G, loss=0.0793] \n",
      "Epoch 285/300: 100%|██████████| 469/469 [00:06<00:00, 76.97batches/s, GPU_mem=0.0503G, loss=0.0803] \n",
      "Epoch 286/300: 100%|██████████| 469/469 [00:06<00:00, 77.68batches/s, GPU_mem=0.0503G, loss=0.0801] \n",
      "Epoch 287/300: 100%|██████████| 469/469 [00:05<00:00, 79.96batches/s, GPU_mem=0.0503G, loss=0.079]  \n",
      "Epoch 288/300: 100%|██████████| 469/469 [00:05<00:00, 80.68batches/s, GPU_mem=0.0503G, loss=0.0795] \n",
      "Epoch 289/300: 100%|██████████| 469/469 [00:05<00:00, 78.98batches/s, GPU_mem=0.0503G, loss=0.0784] \n",
      "Epoch 290/300: 100%|██████████| 469/469 [00:05<00:00, 79.48batches/s, GPU_mem=0.0503G, loss=0.0781] \n",
      "Epoch 291/300: 100%|██████████| 469/469 [00:05<00:00, 78.29batches/s, GPU_mem=0.0503G, loss=0.0778] \n",
      "Epoch 292/300: 100%|██████████| 469/469 [00:05<00:00, 78.64batches/s, GPU_mem=0.0503G, loss=0.078]  \n",
      "Epoch 293/300: 100%|██████████| 469/469 [00:05<00:00, 79.60batches/s, GPU_mem=0.0503G, loss=0.0777] \n",
      "Epoch 294/300: 100%|██████████| 469/469 [00:05<00:00, 79.00batches/s, GPU_mem=0.0503G, loss=0.0775] \n",
      "Epoch 295/300: 100%|██████████| 469/469 [00:06<00:00, 76.62batches/s, GPU_mem=0.0503G, loss=0.0767] \n",
      "Epoch 296/300: 100%|██████████| 469/469 [00:06<00:00, 77.25batches/s, GPU_mem=0.0503G, loss=0.077]  \n",
      "Epoch 297/300: 100%|██████████| 469/469 [00:05<00:00, 78.74batches/s, GPU_mem=0.0503G, loss=0.0767] \n",
      "Epoch 298/300: 100%|██████████| 469/469 [00:05<00:00, 79.26batches/s, GPU_mem=0.0503G, loss=0.0764] \n",
      "Epoch 299/300: 100%|██████████| 469/469 [00:06<00:00, 78.15batches/s, GPU_mem=0.0503G, loss=0.0761] \n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "for epoch in range(epochs):\n",
    "    train_model.train()\n",
    "    mloss = torch.zeros(1, device=device)  # mean_loss\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch}/{epochs}', unit='batches')\n",
    "\n",
    "    for i, (imgs, labels) in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        preds = train_model(imgs)\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        mloss = (mloss * i + loss) / (i + 1)\n",
    "        mem = f'{torch.cuda.memory_reserved() / 1e9 if torch.cuda.is_available() else 0:.3g}G'  # GPU_mem\n",
    "        pbar.set_postfix(loss=mloss.item(), GPU_mem=mem)\n",
    "\n",
    "    ckpt = {  # checkpoint\n",
    "        'epoch': epoch,\n",
    "        'model': deepcopy(train_model).half(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(ckpt, 'LeNet5.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:33:44.155283Z",
     "end_time": "2023-04-08T13:59:24.445522Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "LeNet5(\n  (backbone): Sequential(\n    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n    (1): Tanh()\n    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (3): Tanh()\n    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n    (5): Tanh()\n    (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (7): Tanh()\n    (8): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n    (9): Tanh()\n    (10): Flatten(start_dim=1, end_dim=-1)\n    (11): Linear(in_features=120, out_features=84, bias=True)\n    (12): Tanh()\n    (13): Linear(in_features=84, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load('LeNet5.pt')\n",
    "test_model = ckpt['model'].to(device).float()\n",
    "test_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:59:24.444492Z",
     "end_time": "2023-04-08T13:59:24.474331Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='MNIST',\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=test_transform,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=128,\n",
    "    num_workers=4,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:59:24.475338Z",
     "end_time": "2023-04-08T13:59:24.490170Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 79/79 [00:02<00:00, 28.94batches/s]\n"
     ]
    }
   ],
   "source": [
    "correct = torch.zeros(1, device=device)\n",
    "total = torch.zeros(1, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc='Test', unit='batches')\n",
    "\n",
    "    for i, (imgs, labels) in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        preds = test_model(imgs)\n",
    "        preds = torch.argmax(nn.Softmax(dim=1)(preds), dim=1)  # 将预测结果经softmax后取最大值的序号为预测标签\n",
    "\n",
    "        total += torch.tensor(labels.size(0))\n",
    "        correct += (preds == labels).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:59:24.493082Z",
     "end_time": "2023-04-08T13:59:27.273074Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0.974"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = round((correct / total).item(), 3)\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:59:27.275060Z",
     "end_time": "2023-04-08T13:59:27.318613Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
