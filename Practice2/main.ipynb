{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-08T11:51:43.671675Z",
     "end_time": "2023-04-08T11:51:45.474364Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T11:51:45.476362Z",
     "end_time": "2023-04-08T11:51:46.737729Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_model = LeNet5().to(device)\n",
    "optimizer = torch.optim.Adam(params=train_model.parameters(), lr=1e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=20, gamma=0.5)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T11:51:46.737729Z",
     "end_time": "2023-04-08T11:51:46.817222Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='MNIST',\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=train_transform,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=128,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T11:51:46.818223Z",
     "end_time": "2023-04-08T11:51:46.863676Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/300: 100%|██████████| 469/469 [00:06<00:00, 73.34batches/s, GPU_mem=0.0503G, loss=2.25] \n",
      "Epoch 1/300: 100%|██████████| 469/469 [00:04<00:00, 105.11batches/s, GPU_mem=0.0503G, loss=1.98]\n",
      "Epoch 2/300: 100%|██████████| 469/469 [00:04<00:00, 104.18batches/s, GPU_mem=0.0503G, loss=1.5] \n",
      "Epoch 3/300: 100%|██████████| 469/469 [00:04<00:00, 104.23batches/s, GPU_mem=0.0503G, loss=1.17]\n",
      "Epoch 4/300: 100%|██████████| 469/469 [00:04<00:00, 105.46batches/s, GPU_mem=0.0503G, loss=1]   \n",
      "Epoch 5/300: 100%|██████████| 469/469 [00:06<00:00, 77.84batches/s, GPU_mem=0.0503G, loss=0.902] \n",
      "Epoch 6/300: 100%|██████████| 469/469 [00:06<00:00, 70.31batches/s, GPU_mem=0.0503G, loss=0.838] \n",
      "Epoch 7/300: 100%|██████████| 469/469 [00:06<00:00, 74.93batches/s, GPU_mem=0.0503G, loss=0.791] \n",
      "Epoch 8/300: 100%|██████████| 469/469 [00:05<00:00, 80.92batches/s, GPU_mem=0.0503G, loss=0.754] \n",
      "Epoch 9/300: 100%|██████████| 469/469 [00:06<00:00, 76.56batches/s, GPU_mem=0.0503G, loss=0.724] \n",
      "Epoch 10/300: 100%|██████████| 469/469 [00:05<00:00, 78.29batches/s, GPU_mem=0.0503G, loss=0.698] \n",
      "Epoch 11/300: 100%|██████████| 469/469 [00:06<00:00, 77.26batches/s, GPU_mem=0.0503G, loss=0.676] \n",
      "Epoch 12/300: 100%|██████████| 469/469 [00:06<00:00, 73.64batches/s, GPU_mem=0.0503G, loss=0.656] \n",
      "Epoch 13/300: 100%|██████████| 469/469 [00:05<00:00, 81.87batches/s, GPU_mem=0.0503G, loss=0.638] \n",
      "Epoch 14/300: 100%|██████████| 469/469 [00:05<00:00, 78.51batches/s, GPU_mem=0.0503G, loss=0.622] \n",
      "Epoch 15/300: 100%|██████████| 469/469 [00:05<00:00, 78.95batches/s, GPU_mem=0.0503G, loss=0.607] \n",
      "Epoch 16/300: 100%|██████████| 469/469 [00:05<00:00, 80.18batches/s, GPU_mem=0.0503G, loss=0.593] \n",
      "Epoch 17/300: 100%|██████████| 469/469 [00:05<00:00, 81.00batches/s, GPU_mem=0.0503G, loss=0.58]  \n",
      "Epoch 18/300: 100%|██████████| 469/469 [00:06<00:00, 74.38batches/s, GPU_mem=0.0503G, loss=0.567] \n",
      "Epoch 19/300: 100%|██████████| 469/469 [00:06<00:00, 77.26batches/s, GPU_mem=0.0503G, loss=0.555] \n",
      "Epoch 20/300: 100%|██████████| 469/469 [00:06<00:00, 75.83batches/s, GPU_mem=0.0503G, loss=0.543] \n",
      "Epoch 21/300: 100%|██████████| 469/469 [00:06<00:00, 76.13batches/s, GPU_mem=0.0503G, loss=0.532] \n",
      "Epoch 22/300: 100%|██████████| 469/469 [00:06<00:00, 76.21batches/s, GPU_mem=0.0503G, loss=0.521] \n",
      "Epoch 23/300: 100%|██████████| 469/469 [00:06<00:00, 76.87batches/s, GPU_mem=0.0503G, loss=0.51]  \n",
      "Epoch 24/300: 100%|██████████| 469/469 [00:06<00:00, 77.21batches/s, GPU_mem=0.0503G, loss=0.5]   \n",
      "Epoch 25/300: 100%|██████████| 469/469 [00:06<00:00, 75.64batches/s, GPU_mem=0.0503G, loss=0.489] \n",
      "Epoch 26/300: 100%|██████████| 469/469 [00:04<00:00, 104.60batches/s, GPU_mem=0.0503G, loss=0.48] \n",
      "Epoch 27/300: 100%|██████████| 469/469 [00:04<00:00, 104.25batches/s, GPU_mem=0.0503G, loss=0.47] \n",
      "Epoch 28/300: 100%|██████████| 469/469 [00:04<00:00, 108.01batches/s, GPU_mem=0.0503G, loss=0.461]\n",
      "Epoch 29/300: 100%|██████████| 469/469 [00:04<00:00, 103.71batches/s, GPU_mem=0.0503G, loss=0.452]\n",
      "Epoch 30/300: 100%|██████████| 469/469 [00:04<00:00, 106.75batches/s, GPU_mem=0.0503G, loss=0.444]\n",
      "Epoch 31/300: 100%|██████████| 469/469 [00:04<00:00, 105.50batches/s, GPU_mem=0.0503G, loss=0.435]\n",
      "Epoch 32/300: 100%|██████████| 469/469 [00:04<00:00, 104.45batches/s, GPU_mem=0.0503G, loss=0.427]\n",
      "Epoch 33/300: 100%|██████████| 469/469 [00:04<00:00, 103.09batches/s, GPU_mem=0.0503G, loss=0.419]\n",
      "Epoch 34/300: 100%|██████████| 469/469 [00:04<00:00, 100.37batches/s, GPU_mem=0.0503G, loss=0.411]\n",
      "Epoch 35/300: 100%|██████████| 469/469 [00:04<00:00, 101.70batches/s, GPU_mem=0.0503G, loss=0.404]\n",
      "Epoch 36/300: 100%|██████████| 469/469 [00:04<00:00, 107.54batches/s, GPU_mem=0.0503G, loss=0.397]\n",
      "Epoch 37/300: 100%|██████████| 469/469 [00:04<00:00, 105.35batches/s, GPU_mem=0.0503G, loss=0.39] \n",
      "Epoch 38/300: 100%|██████████| 469/469 [00:04<00:00, 110.92batches/s, GPU_mem=0.0503G, loss=0.383]\n",
      "Epoch 39/300: 100%|██████████| 469/469 [00:04<00:00, 103.68batches/s, GPU_mem=0.0503G, loss=0.377]\n",
      "Epoch 40/300: 100%|██████████| 469/469 [00:04<00:00, 108.16batches/s, GPU_mem=0.0503G, loss=0.371]\n",
      "Epoch 41/300: 100%|██████████| 469/469 [00:04<00:00, 106.09batches/s, GPU_mem=0.0503G, loss=0.364]\n",
      "Epoch 42/300: 100%|██████████| 469/469 [00:04<00:00, 109.60batches/s, GPU_mem=0.0503G, loss=0.358]\n",
      "Epoch 43/300: 100%|██████████| 469/469 [00:05<00:00, 85.58batches/s, GPU_mem=0.0503G, loss=0.352] \n",
      "Epoch 44/300: 100%|██████████| 469/469 [00:05<00:00, 82.93batches/s, GPU_mem=0.0503G, loss=0.346] \n",
      "Epoch 45/300: 100%|██████████| 469/469 [00:05<00:00, 80.85batches/s, GPU_mem=0.0503G, loss=0.342] \n",
      "Epoch 46/300: 100%|██████████| 469/469 [00:05<00:00, 82.70batches/s, GPU_mem=0.0503G, loss=0.336] \n",
      "Epoch 47/300: 100%|██████████| 469/469 [00:05<00:00, 82.44batches/s, GPU_mem=0.0503G, loss=0.331] \n",
      "Epoch 48/300: 100%|██████████| 469/469 [00:05<00:00, 82.24batches/s, GPU_mem=0.0503G, loss=0.326] \n",
      "Epoch 49/300: 100%|██████████| 469/469 [00:05<00:00, 84.65batches/s, GPU_mem=0.0503G, loss=0.321] \n",
      "Epoch 50/300: 100%|██████████| 469/469 [00:05<00:00, 81.87batches/s, GPU_mem=0.0503G, loss=0.316] \n",
      "Epoch 51/300: 100%|██████████| 469/469 [00:05<00:00, 82.19batches/s, GPU_mem=0.0503G, loss=0.312] \n",
      "Epoch 52/300: 100%|██████████| 469/469 [00:05<00:00, 83.06batches/s, GPU_mem=0.0503G, loss=0.307] \n",
      "Epoch 53/300: 100%|██████████| 469/469 [00:06<00:00, 77.69batches/s, GPU_mem=0.0503G, loss=0.303] \n",
      "Epoch 54/300: 100%|██████████| 469/469 [00:05<00:00, 82.70batches/s, GPU_mem=0.0503G, loss=0.298] \n",
      "Epoch 55/300: 100%|██████████| 469/469 [00:05<00:00, 78.84batches/s, GPU_mem=0.0503G, loss=0.295] \n",
      "Epoch 56/300: 100%|██████████| 469/469 [00:05<00:00, 79.88batches/s, GPU_mem=0.0503G, loss=0.291] \n",
      "Epoch 57/300: 100%|██████████| 469/469 [00:05<00:00, 82.24batches/s, GPU_mem=0.0503G, loss=0.287] \n",
      "Epoch 58/300: 100%|██████████| 469/469 [00:05<00:00, 82.29batches/s, GPU_mem=0.0503G, loss=0.283] \n",
      "Epoch 59/300: 100%|██████████| 469/469 [00:06<00:00, 77.32batches/s, GPU_mem=0.0503G, loss=0.28]  \n",
      "Epoch 60/300: 100%|██████████| 469/469 [00:05<00:00, 79.22batches/s, GPU_mem=0.0503G, loss=0.277] \n",
      "Epoch 61/300: 100%|██████████| 469/469 [00:05<00:00, 80.98batches/s, GPU_mem=0.0503G, loss=0.273] \n",
      "Epoch 62/300: 100%|██████████| 469/469 [00:05<00:00, 79.40batches/s, GPU_mem=0.0503G, loss=0.269] \n",
      "Epoch 63/300: 100%|██████████| 469/469 [00:05<00:00, 78.64batches/s, GPU_mem=0.0503G, loss=0.266] \n",
      "Epoch 64/300: 100%|██████████| 469/469 [00:06<00:00, 75.46batches/s, GPU_mem=0.0503G, loss=0.263] \n",
      "Epoch 65/300: 100%|██████████| 469/469 [00:05<00:00, 80.43batches/s, GPU_mem=0.0503G, loss=0.26]  \n",
      "Epoch 66/300: 100%|██████████| 469/469 [00:05<00:00, 78.35batches/s, GPU_mem=0.0503G, loss=0.257] \n",
      "Epoch 67/300: 100%|██████████| 469/469 [00:05<00:00, 78.96batches/s, GPU_mem=0.0503G, loss=0.254] \n",
      "Epoch 68/300: 100%|██████████| 469/469 [00:05<00:00, 80.07batches/s, GPU_mem=0.0503G, loss=0.251] \n",
      "Epoch 69/300: 100%|██████████| 469/469 [00:05<00:00, 81.52batches/s, GPU_mem=0.0503G, loss=0.248] \n",
      "Epoch 70/300: 100%|██████████| 469/469 [00:05<00:00, 83.23batches/s, GPU_mem=0.0503G, loss=0.246] \n",
      "Epoch 71/300: 100%|██████████| 469/469 [00:05<00:00, 82.94batches/s, GPU_mem=0.0503G, loss=0.243] \n",
      "Epoch 72/300: 100%|██████████| 469/469 [00:05<00:00, 82.70batches/s, GPU_mem=0.0503G, loss=0.24]  \n",
      "Epoch 73/300: 100%|██████████| 469/469 [00:05<00:00, 80.29batches/s, GPU_mem=0.0503G, loss=0.238] \n",
      "Epoch 74/300: 100%|██████████| 469/469 [00:05<00:00, 83.50batches/s, GPU_mem=0.0503G, loss=0.235] \n",
      "Epoch 75/300: 100%|██████████| 469/469 [00:05<00:00, 80.00batches/s, GPU_mem=0.0503G, loss=0.233] \n",
      "Epoch 76/300: 100%|██████████| 469/469 [00:05<00:00, 79.16batches/s, GPU_mem=0.0503G, loss=0.23]  \n",
      "Epoch 77/300: 100%|██████████| 469/469 [00:05<00:00, 80.04batches/s, GPU_mem=0.0503G, loss=0.228] \n",
      "Epoch 78/300: 100%|██████████| 469/469 [00:05<00:00, 81.49batches/s, GPU_mem=0.0503G, loss=0.226] \n",
      "Epoch 79/300: 100%|██████████| 469/469 [00:05<00:00, 82.90batches/s, GPU_mem=0.0503G, loss=0.224] \n",
      "Epoch 80/300: 100%|██████████| 469/469 [00:05<00:00, 83.19batches/s, GPU_mem=0.0503G, loss=0.221] \n",
      "Epoch 81/300: 100%|██████████| 469/469 [00:05<00:00, 85.79batches/s, GPU_mem=0.0503G, loss=0.219] \n",
      "Epoch 82/300: 100%|██████████| 469/469 [00:05<00:00, 82.09batches/s, GPU_mem=0.0503G, loss=0.217] \n",
      "Epoch 83/300: 100%|██████████| 469/469 [00:05<00:00, 81.50batches/s, GPU_mem=0.0503G, loss=0.215] \n",
      "Epoch 84/300: 100%|██████████| 469/469 [00:05<00:00, 84.38batches/s, GPU_mem=0.0503G, loss=0.212] \n",
      "Epoch 85/300: 100%|██████████| 469/469 [00:05<00:00, 83.99batches/s, GPU_mem=0.0503G, loss=0.211] \n",
      "Epoch 86/300: 100%|██████████| 469/469 [00:05<00:00, 84.32batches/s, GPU_mem=0.0503G, loss=0.209] \n",
      "Epoch 87/300: 100%|██████████| 469/469 [00:05<00:00, 78.92batches/s, GPU_mem=0.0503G, loss=0.207] \n",
      "Epoch 88/300: 100%|██████████| 469/469 [00:05<00:00, 80.97batches/s, GPU_mem=0.0503G, loss=0.206] \n",
      "Epoch 89/300: 100%|██████████| 469/469 [00:06<00:00, 76.61batches/s, GPU_mem=0.0503G, loss=0.204] \n",
      "Epoch 90/300: 100%|██████████| 469/469 [00:06<00:00, 72.03batches/s, GPU_mem=0.0503G, loss=0.202] \n",
      "Epoch 91/300: 100%|██████████| 469/469 [00:06<00:00, 74.57batches/s, GPU_mem=0.0503G, loss=0.2]   \n",
      "Epoch 92/300: 100%|██████████| 469/469 [00:06<00:00, 77.63batches/s, GPU_mem=0.0503G, loss=0.198] \n",
      "Epoch 93/300: 100%|██████████| 469/469 [00:05<00:00, 79.30batches/s, GPU_mem=0.0503G, loss=0.196] \n",
      "Epoch 94/300: 100%|██████████| 469/469 [00:05<00:00, 78.67batches/s, GPU_mem=0.0503G, loss=0.194] \n",
      "Epoch 95/300: 100%|██████████| 469/469 [00:05<00:00, 79.44batches/s, GPU_mem=0.0503G, loss=0.193] \n",
      "Epoch 96/300: 100%|██████████| 469/469 [00:06<00:00, 77.92batches/s, GPU_mem=0.0503G, loss=0.191] \n",
      "Epoch 97/300: 100%|██████████| 469/469 [00:06<00:00, 77.46batches/s, GPU_mem=0.0503G, loss=0.189] \n",
      "Epoch 98/300: 100%|██████████| 469/469 [00:06<00:00, 77.89batches/s, GPU_mem=0.0503G, loss=0.188] \n",
      "Epoch 99/300: 100%|██████████| 469/469 [00:05<00:00, 79.96batches/s, GPU_mem=0.0503G, loss=0.186] \n",
      "Epoch 100/300: 100%|██████████| 469/469 [00:06<00:00, 76.45batches/s, GPU_mem=0.0503G, loss=0.185] \n",
      "Epoch 101/300: 100%|██████████| 469/469 [00:05<00:00, 78.21batches/s, GPU_mem=0.0503G, loss=0.183] \n",
      "Epoch 102/300: 100%|██████████| 469/469 [00:06<00:00, 76.49batches/s, GPU_mem=0.0503G, loss=0.182] \n",
      "Epoch 103/300: 100%|██████████| 469/469 [00:06<00:00, 76.76batches/s, GPU_mem=0.0503G, loss=0.18]  \n",
      "Epoch 104/300: 100%|██████████| 469/469 [00:06<00:00, 75.76batches/s, GPU_mem=0.0503G, loss=0.179] \n",
      "Epoch 105/300: 100%|██████████| 469/469 [00:06<00:00, 77.17batches/s, GPU_mem=0.0503G, loss=0.178] \n",
      "Epoch 106/300: 100%|██████████| 469/469 [00:06<00:00, 74.57batches/s, GPU_mem=0.0503G, loss=0.177] \n",
      "Epoch 107/300: 100%|██████████| 469/469 [00:06<00:00, 75.73batches/s, GPU_mem=0.0503G, loss=0.175] \n",
      "Epoch 108/300: 100%|██████████| 469/469 [00:05<00:00, 79.96batches/s, GPU_mem=0.0503G, loss=0.174] \n",
      "Epoch 109/300: 100%|██████████| 469/469 [00:05<00:00, 80.07batches/s, GPU_mem=0.0503G, loss=0.173] \n",
      "Epoch 110/300: 100%|██████████| 469/469 [00:05<00:00, 81.08batches/s, GPU_mem=0.0503G, loss=0.172] \n",
      "Epoch 111/300: 100%|██████████| 469/469 [00:05<00:00, 82.32batches/s, GPU_mem=0.0503G, loss=0.17]  \n",
      "Epoch 112/300: 100%|██████████| 469/469 [00:05<00:00, 80.01batches/s, GPU_mem=0.0503G, loss=0.168] \n",
      "Epoch 113/300: 100%|██████████| 469/469 [00:05<00:00, 81.09batches/s, GPU_mem=0.0503G, loss=0.168] \n",
      "Epoch 114/300: 100%|██████████| 469/469 [00:05<00:00, 78.22batches/s, GPU_mem=0.0503G, loss=0.167] \n",
      "Epoch 115/300: 100%|██████████| 469/469 [00:05<00:00, 79.07batches/s, GPU_mem=0.0503G, loss=0.165] \n",
      "Epoch 116/300: 100%|██████████| 469/469 [00:05<00:00, 81.05batches/s, GPU_mem=0.0503G, loss=0.164] \n",
      "Epoch 117/300: 100%|██████████| 469/469 [00:05<00:00, 79.23batches/s, GPU_mem=0.0503G, loss=0.163] \n",
      "Epoch 118/300: 100%|██████████| 469/469 [00:05<00:00, 79.97batches/s, GPU_mem=0.0503G, loss=0.162] \n",
      "Epoch 119/300: 100%|██████████| 469/469 [00:05<00:00, 82.50batches/s, GPU_mem=0.0503G, loss=0.161] \n",
      "Epoch 120/300: 100%|██████████| 469/469 [00:05<00:00, 81.09batches/s, GPU_mem=0.0503G, loss=0.16]  \n",
      "Epoch 121/300: 100%|██████████| 469/469 [00:05<00:00, 81.07batches/s, GPU_mem=0.0503G, loss=0.159] \n",
      "Epoch 122/300: 100%|██████████| 469/469 [00:05<00:00, 78.73batches/s, GPU_mem=0.0503G, loss=0.158] \n",
      "Epoch 123/300: 100%|██████████| 469/469 [00:05<00:00, 81.82batches/s, GPU_mem=0.0503G, loss=0.157] \n",
      "Epoch 124/300: 100%|██████████| 469/469 [00:05<00:00, 78.90batches/s, GPU_mem=0.0503G, loss=0.156] \n",
      "Epoch 125/300: 100%|██████████| 469/469 [00:05<00:00, 79.70batches/s, GPU_mem=0.0503G, loss=0.155] \n",
      "Epoch 126/300: 100%|██████████| 469/469 [00:05<00:00, 80.62batches/s, GPU_mem=0.0503G, loss=0.154] \n",
      "Epoch 127/300: 100%|██████████| 469/469 [00:05<00:00, 81.83batches/s, GPU_mem=0.0503G, loss=0.153] \n",
      "Epoch 128/300: 100%|██████████| 469/469 [00:05<00:00, 79.90batches/s, GPU_mem=0.0503G, loss=0.152] \n",
      "Epoch 129/300: 100%|██████████| 469/469 [00:05<00:00, 78.76batches/s, GPU_mem=0.0503G, loss=0.151] \n",
      "Epoch 130/300: 100%|██████████| 469/469 [00:05<00:00, 81.81batches/s, GPU_mem=0.0503G, loss=0.15]  \n",
      "Epoch 131/300: 100%|██████████| 469/469 [00:05<00:00, 81.45batches/s, GPU_mem=0.0503G, loss=0.149] \n",
      "Epoch 132/300: 100%|██████████| 469/469 [00:06<00:00, 78.09batches/s, GPU_mem=0.0503G, loss=0.148] \n",
      "Epoch 133/300: 100%|██████████| 469/469 [00:05<00:00, 80.98batches/s, GPU_mem=0.0503G, loss=0.148] \n",
      "Epoch 134/300: 100%|██████████| 469/469 [00:05<00:00, 81.29batches/s, GPU_mem=0.0503G, loss=0.146] \n",
      "Epoch 135/300: 100%|██████████| 469/469 [00:05<00:00, 79.31batches/s, GPU_mem=0.0503G, loss=0.145] \n",
      "Epoch 136/300: 100%|██████████| 469/469 [00:05<00:00, 81.70batches/s, GPU_mem=0.0503G, loss=0.145] \n",
      "Epoch 137/300: 100%|██████████| 469/469 [00:05<00:00, 81.61batches/s, GPU_mem=0.0503G, loss=0.144] \n",
      "Epoch 138/300: 100%|██████████| 469/469 [00:05<00:00, 81.44batches/s, GPU_mem=0.0503G, loss=0.143] \n",
      "Epoch 139/300: 100%|██████████| 469/469 [00:05<00:00, 81.57batches/s, GPU_mem=0.0503G, loss=0.142] \n",
      "Epoch 140/300: 100%|██████████| 469/469 [00:05<00:00, 82.06batches/s, GPU_mem=0.0503G, loss=0.141] \n",
      "Epoch 141/300: 100%|██████████| 469/469 [00:05<00:00, 79.30batches/s, GPU_mem=0.0503G, loss=0.141] \n",
      "Epoch 142/300: 100%|██████████| 469/469 [00:05<00:00, 81.38batches/s, GPU_mem=0.0503G, loss=0.14]  \n",
      "Epoch 143/300: 100%|██████████| 469/469 [00:05<00:00, 80.70batches/s, GPU_mem=0.0503G, loss=0.139] \n",
      "Epoch 144/300: 100%|██████████| 469/469 [00:05<00:00, 79.63batches/s, GPU_mem=0.0503G, loss=0.138] \n",
      "Epoch 145/300: 100%|██████████| 469/469 [00:05<00:00, 79.04batches/s, GPU_mem=0.0503G, loss=0.138] \n",
      "Epoch 146/300: 100%|██████████| 469/469 [00:05<00:00, 79.11batches/s, GPU_mem=0.0503G, loss=0.137] \n",
      "Epoch 147/300: 100%|██████████| 469/469 [00:05<00:00, 80.89batches/s, GPU_mem=0.0503G, loss=0.137] \n",
      "Epoch 148/300: 100%|██████████| 469/469 [00:05<00:00, 79.60batches/s, GPU_mem=0.0503G, loss=0.136] \n",
      "Epoch 149/300: 100%|██████████| 469/469 [00:05<00:00, 82.02batches/s, GPU_mem=0.0503G, loss=0.135] \n",
      "Epoch 150/300: 100%|██████████| 469/469 [00:05<00:00, 79.78batches/s, GPU_mem=0.0503G, loss=0.134] \n",
      "Epoch 151/300: 100%|██████████| 469/469 [00:05<00:00, 81.43batches/s, GPU_mem=0.0503G, loss=0.134] \n",
      "Epoch 152/300: 100%|██████████| 469/469 [00:05<00:00, 82.29batches/s, GPU_mem=0.0503G, loss=0.132] \n",
      "Epoch 153/300: 100%|██████████| 469/469 [00:05<00:00, 81.45batches/s, GPU_mem=0.0503G, loss=0.132] \n",
      "Epoch 154/300: 100%|██████████| 469/469 [00:05<00:00, 80.55batches/s, GPU_mem=0.0503G, loss=0.131] \n",
      "Epoch 155/300: 100%|██████████| 469/469 [00:05<00:00, 82.79batches/s, GPU_mem=0.0503G, loss=0.13]  \n",
      "Epoch 156/300: 100%|██████████| 469/469 [00:05<00:00, 81.59batches/s, GPU_mem=0.0503G, loss=0.13]  \n",
      "Epoch 157/300: 100%|██████████| 469/469 [00:05<00:00, 80.62batches/s, GPU_mem=0.0503G, loss=0.13]  \n",
      "Epoch 158/300: 100%|██████████| 469/469 [00:05<00:00, 81.70batches/s, GPU_mem=0.0503G, loss=0.129] \n",
      "Epoch 159/300: 100%|██████████| 469/469 [00:05<00:00, 82.56batches/s, GPU_mem=0.0503G, loss=0.128] \n",
      "Epoch 160/300: 100%|██████████| 469/469 [00:05<00:00, 79.37batches/s, GPU_mem=0.0503G, loss=0.128] \n",
      "Epoch 161/300: 100%|██████████| 469/469 [00:05<00:00, 81.18batches/s, GPU_mem=0.0503G, loss=0.126] \n",
      "Epoch 162/300: 100%|██████████| 469/469 [00:05<00:00, 78.23batches/s, GPU_mem=0.0503G, loss=0.127] \n",
      "Epoch 163/300: 100%|██████████| 469/469 [00:05<00:00, 82.06batches/s, GPU_mem=0.0503G, loss=0.125] \n",
      "Epoch 164/300: 100%|██████████| 469/469 [00:05<00:00, 82.69batches/s, GPU_mem=0.0503G, loss=0.125] \n",
      "Epoch 165/300: 100%|██████████| 469/469 [00:05<00:00, 81.57batches/s, GPU_mem=0.0503G, loss=0.124] \n",
      "Epoch 166/300: 100%|██████████| 469/469 [00:06<00:00, 77.93batches/s, GPU_mem=0.0503G, loss=0.123] \n",
      "Epoch 167/300: 100%|██████████| 469/469 [00:05<00:00, 80.03batches/s, GPU_mem=0.0503G, loss=0.123] \n",
      "Epoch 168/300: 100%|██████████| 469/469 [00:05<00:00, 80.95batches/s, GPU_mem=0.0503G, loss=0.122] \n",
      "Epoch 169/300: 100%|██████████| 469/469 [00:05<00:00, 81.65batches/s, GPU_mem=0.0503G, loss=0.122] \n",
      "Epoch 170/300: 100%|██████████| 469/469 [00:05<00:00, 82.31batches/s, GPU_mem=0.0503G, loss=0.121] \n",
      "Epoch 171/300: 100%|██████████| 469/469 [00:05<00:00, 81.61batches/s, GPU_mem=0.0503G, loss=0.121] \n",
      "Epoch 172/300: 100%|██████████| 469/469 [00:05<00:00, 83.90batches/s, GPU_mem=0.0503G, loss=0.12]  \n",
      "Epoch 173/300: 100%|██████████| 469/469 [00:05<00:00, 79.97batches/s, GPU_mem=0.0503G, loss=0.12]  \n",
      "Epoch 174/300: 100%|██████████| 469/469 [00:05<00:00, 82.50batches/s, GPU_mem=0.0503G, loss=0.119] \n",
      "Epoch 175/300: 100%|██████████| 469/469 [00:05<00:00, 80.80batches/s, GPU_mem=0.0503G, loss=0.118] \n",
      "Epoch 176/300: 100%|██████████| 469/469 [00:05<00:00, 79.74batches/s, GPU_mem=0.0503G, loss=0.118] \n",
      "Epoch 177/300: 100%|██████████| 469/469 [00:05<00:00, 80.48batches/s, GPU_mem=0.0503G, loss=0.117] \n",
      "Epoch 178/300: 100%|██████████| 469/469 [00:05<00:00, 84.86batches/s, GPU_mem=0.0503G, loss=0.116] \n",
      "Epoch 179/300: 100%|██████████| 469/469 [00:05<00:00, 81.51batches/s, GPU_mem=0.0503G, loss=0.116] \n",
      "Epoch 180/300: 100%|██████████| 469/469 [00:05<00:00, 82.05batches/s, GPU_mem=0.0503G, loss=0.115] \n",
      "Epoch 181/300: 100%|██████████| 469/469 [00:05<00:00, 81.32batches/s, GPU_mem=0.0503G, loss=0.115] \n",
      "Epoch 182/300: 100%|██████████| 469/469 [00:05<00:00, 81.49batches/s, GPU_mem=0.0503G, loss=0.115] \n",
      "Epoch 183/300: 100%|██████████| 469/469 [00:05<00:00, 82.32batches/s, GPU_mem=0.0503G, loss=0.114] \n",
      "Epoch 184/300: 100%|██████████| 469/469 [00:05<00:00, 82.01batches/s, GPU_mem=0.0503G, loss=0.114] \n",
      "Epoch 185/300: 100%|██████████| 469/469 [00:06<00:00, 77.52batches/s, GPU_mem=0.0503G, loss=0.113] \n",
      "Epoch 186/300: 100%|██████████| 469/469 [00:06<00:00, 77.24batches/s, GPU_mem=0.0503G, loss=0.112] \n",
      "Epoch 187/300: 100%|██████████| 469/469 [00:06<00:00, 76.80batches/s, GPU_mem=0.0503G, loss=0.112] \n",
      "Epoch 188/300: 100%|██████████| 469/469 [00:06<00:00, 77.15batches/s, GPU_mem=0.0503G, loss=0.112] \n",
      "Epoch 189/300: 100%|██████████| 469/469 [00:05<00:00, 79.75batches/s, GPU_mem=0.0503G, loss=0.111] \n",
      "Epoch 190/300: 100%|██████████| 469/469 [00:05<00:00, 82.38batches/s, GPU_mem=0.0503G, loss=0.111] \n",
      "Epoch 191/300: 100%|██████████| 469/469 [00:05<00:00, 80.67batches/s, GPU_mem=0.0503G, loss=0.11]  \n",
      "Epoch 192/300: 100%|██████████| 469/469 [00:05<00:00, 81.57batches/s, GPU_mem=0.0503G, loss=0.11]  \n",
      "Epoch 193/300: 100%|██████████| 469/469 [00:05<00:00, 80.35batches/s, GPU_mem=0.0503G, loss=0.109] \n",
      "Epoch 194/300: 100%|██████████| 469/469 [00:05<00:00, 82.92batches/s, GPU_mem=0.0503G, loss=0.108] \n",
      "Epoch 195/300: 100%|██████████| 469/469 [00:05<00:00, 82.37batches/s, GPU_mem=0.0503G, loss=0.108] \n",
      "Epoch 196/300: 100%|██████████| 469/469 [00:05<00:00, 79.28batches/s, GPU_mem=0.0503G, loss=0.108] \n",
      "Epoch 197/300: 100%|██████████| 469/469 [00:05<00:00, 80.97batches/s, GPU_mem=0.0503G, loss=0.107] \n",
      "Epoch 198/300: 100%|██████████| 469/469 [00:05<00:00, 84.71batches/s, GPU_mem=0.0503G, loss=0.107] \n",
      "Epoch 199/300: 100%|██████████| 469/469 [00:05<00:00, 80.64batches/s, GPU_mem=0.0503G, loss=0.106] \n",
      "Epoch 200/300: 100%|██████████| 469/469 [00:05<00:00, 79.56batches/s, GPU_mem=0.0503G, loss=0.106] \n",
      "Epoch 201/300: 100%|██████████| 469/469 [00:05<00:00, 81.66batches/s, GPU_mem=0.0503G, loss=0.106] \n",
      "Epoch 202/300: 100%|██████████| 469/469 [00:05<00:00, 78.79batches/s, GPU_mem=0.0503G, loss=0.105] \n",
      "Epoch 203/300: 100%|██████████| 469/469 [00:05<00:00, 81.59batches/s, GPU_mem=0.0503G, loss=0.104] \n",
      "Epoch 204/300: 100%|██████████| 469/469 [00:05<00:00, 81.24batches/s, GPU_mem=0.0503G, loss=0.104] \n",
      "Epoch 205/300: 100%|██████████| 469/469 [00:05<00:00, 82.86batches/s, GPU_mem=0.0503G, loss=0.104] \n",
      "Epoch 206/300: 100%|██████████| 469/469 [00:05<00:00, 82.73batches/s, GPU_mem=0.0503G, loss=0.104] \n",
      "Epoch 207/300: 100%|██████████| 469/469 [00:05<00:00, 80.67batches/s, GPU_mem=0.0503G, loss=0.103]  \n",
      "Epoch 208/300: 100%|██████████| 469/469 [00:05<00:00, 79.69batches/s, GPU_mem=0.0503G, loss=0.102] \n",
      "Epoch 209/300: 100%|██████████| 469/469 [00:05<00:00, 80.56batches/s, GPU_mem=0.0503G, loss=0.102]  \n",
      "Epoch 210/300: 100%|██████████| 469/469 [00:05<00:00, 79.97batches/s, GPU_mem=0.0503G, loss=0.102]  \n",
      "Epoch 211/300: 100%|██████████| 469/469 [00:05<00:00, 81.05batches/s, GPU_mem=0.0503G, loss=0.102] \n",
      "Epoch 212/300: 100%|██████████| 469/469 [00:05<00:00, 82.73batches/s, GPU_mem=0.0503G, loss=0.101]  \n",
      "Epoch 213/300: 100%|██████████| 469/469 [00:05<00:00, 81.13batches/s, GPU_mem=0.0503G, loss=0.1]    \n",
      "Epoch 214/300: 100%|██████████| 469/469 [00:05<00:00, 79.16batches/s, GPU_mem=0.0503G, loss=0.1]    \n",
      "Epoch 215/300: 100%|██████████| 469/469 [00:05<00:00, 80.34batches/s, GPU_mem=0.0503G, loss=0.0998] \n",
      "Epoch 216/300: 100%|██████████| 469/469 [00:05<00:00, 80.81batches/s, GPU_mem=0.0503G, loss=0.0998] \n",
      "Epoch 217/300: 100%|██████████| 469/469 [00:05<00:00, 80.44batches/s, GPU_mem=0.0503G, loss=0.0993] \n",
      "Epoch 218/300: 100%|██████████| 469/469 [00:06<00:00, 77.90batches/s, GPU_mem=0.0503G, loss=0.0984] \n",
      "Epoch 219/300: 100%|██████████| 469/469 [00:05<00:00, 81.38batches/s, GPU_mem=0.0503G, loss=0.0979] \n",
      "Epoch 220/300: 100%|██████████| 469/469 [00:05<00:00, 80.39batches/s, GPU_mem=0.0503G, loss=0.0981] \n",
      "Epoch 221/300: 100%|██████████| 469/469 [00:05<00:00, 81.24batches/s, GPU_mem=0.0503G, loss=0.0979] \n",
      "Epoch 222/300: 100%|██████████| 469/469 [00:05<00:00, 78.99batches/s, GPU_mem=0.0503G, loss=0.0974] \n",
      "Epoch 223/300: 100%|██████████| 469/469 [00:06<00:00, 76.84batches/s, GPU_mem=0.0503G, loss=0.0966] \n",
      "Epoch 224/300: 100%|██████████| 469/469 [00:05<00:00, 80.87batches/s, GPU_mem=0.0503G, loss=0.0967] \n",
      "Epoch 225/300: 100%|██████████| 469/469 [00:06<00:00, 78.03batches/s, GPU_mem=0.0503G, loss=0.0957] \n",
      "Epoch 226/300: 100%|██████████| 469/469 [00:06<00:00, 76.69batches/s, GPU_mem=0.0503G, loss=0.0955] \n",
      "Epoch 227/300: 100%|██████████| 469/469 [00:05<00:00, 78.70batches/s, GPU_mem=0.0503G, loss=0.0946] \n",
      "Epoch 228/300: 100%|██████████| 469/469 [00:05<00:00, 78.28batches/s, GPU_mem=0.0503G, loss=0.0952] \n",
      "Epoch 229/300: 100%|██████████| 469/469 [00:05<00:00, 79.90batches/s, GPU_mem=0.0503G, loss=0.0945] \n",
      "Epoch 230/300: 100%|██████████| 469/469 [00:05<00:00, 79.00batches/s, GPU_mem=0.0503G, loss=0.0939] \n",
      "Epoch 231/300: 100%|██████████| 469/469 [00:05<00:00, 80.95batches/s, GPU_mem=0.0503G, loss=0.094]  \n",
      "Epoch 232/300: 100%|██████████| 469/469 [00:05<00:00, 79.71batches/s, GPU_mem=0.0503G, loss=0.0934] \n",
      "Epoch 233/300: 100%|██████████| 469/469 [00:05<00:00, 80.12batches/s, GPU_mem=0.0503G, loss=0.0933] \n",
      "Epoch 234/300: 100%|██████████| 469/469 [00:05<00:00, 79.27batches/s, GPU_mem=0.0503G, loss=0.0929] \n",
      "Epoch 235/300: 100%|██████████| 469/469 [00:05<00:00, 79.34batches/s, GPU_mem=0.0503G, loss=0.0924] \n",
      "Epoch 236/300: 100%|██████████| 469/469 [00:05<00:00, 81.64batches/s, GPU_mem=0.0503G, loss=0.0915] \n",
      "Epoch 237/300: 100%|██████████| 469/469 [00:05<00:00, 79.40batches/s, GPU_mem=0.0503G, loss=0.0914] \n",
      "Epoch 238/300: 100%|██████████| 469/469 [00:05<00:00, 80.91batches/s, GPU_mem=0.0503G, loss=0.0914] \n",
      "Epoch 239/300: 100%|██████████| 469/469 [00:06<00:00, 78.00batches/s, GPU_mem=0.0503G, loss=0.0917] \n",
      "Epoch 240/300: 100%|██████████| 469/469 [00:06<00:00, 77.83batches/s, GPU_mem=0.0503G, loss=0.0902] \n",
      "Epoch 241/300: 100%|██████████| 469/469 [00:05<00:00, 79.80batches/s, GPU_mem=0.0503G, loss=0.0904] \n",
      "Epoch 242/300: 100%|██████████| 469/469 [00:05<00:00, 78.40batches/s, GPU_mem=0.0503G, loss=0.0895] \n",
      "Epoch 243/300: 100%|██████████| 469/469 [00:05<00:00, 79.22batches/s, GPU_mem=0.0503G, loss=0.0898] \n",
      "Epoch 244/300: 100%|██████████| 469/469 [00:05<00:00, 78.66batches/s, GPU_mem=0.0503G, loss=0.0892] \n",
      "Epoch 245/300: 100%|██████████| 469/469 [00:05<00:00, 81.90batches/s, GPU_mem=0.0503G, loss=0.0888] \n",
      "Epoch 246/300: 100%|██████████| 469/469 [00:05<00:00, 80.57batches/s, GPU_mem=0.0503G, loss=0.0882] \n",
      "Epoch 247/300: 100%|██████████| 469/469 [00:05<00:00, 80.39batches/s, GPU_mem=0.0503G, loss=0.0881] \n",
      "Epoch 248/300: 100%|██████████| 469/469 [00:05<00:00, 78.46batches/s, GPU_mem=0.0503G, loss=0.0883] \n",
      "Epoch 249/300: 100%|██████████| 469/469 [00:05<00:00, 80.14batches/s, GPU_mem=0.0503G, loss=0.0871] \n",
      "Epoch 250/300: 100%|██████████| 469/469 [00:05<00:00, 79.87batches/s, GPU_mem=0.0503G, loss=0.0874] \n",
      "Epoch 251/300: 100%|██████████| 469/469 [00:05<00:00, 78.30batches/s, GPU_mem=0.0503G, loss=0.0876] \n",
      "Epoch 252/300: 100%|██████████| 469/469 [00:05<00:00, 79.09batches/s, GPU_mem=0.0503G, loss=0.0862] \n",
      "Epoch 253/300: 100%|██████████| 469/469 [00:05<00:00, 80.87batches/s, GPU_mem=0.0503G, loss=0.0862] \n",
      "Epoch 254/300: 100%|██████████| 469/469 [00:06<00:00, 77.69batches/s, GPU_mem=0.0503G, loss=0.0866] \n",
      "Epoch 255/300: 100%|██████████| 469/469 [00:06<00:00, 78.04batches/s, GPU_mem=0.0503G, loss=0.0856] \n",
      "Epoch 256/300: 100%|██████████| 469/469 [00:05<00:00, 79.04batches/s, GPU_mem=0.0503G, loss=0.0855] \n",
      "Epoch 257/300: 100%|██████████| 469/469 [00:06<00:00, 78.03batches/s, GPU_mem=0.0503G, loss=0.0857] \n",
      "Epoch 258/300: 100%|██████████| 469/469 [00:05<00:00, 78.56batches/s, GPU_mem=0.0503G, loss=0.085]  \n",
      "Epoch 259/300: 100%|██████████| 469/469 [00:06<00:00, 77.98batches/s, GPU_mem=0.0503G, loss=0.0846] \n",
      "Epoch 260/300: 100%|██████████| 469/469 [00:05<00:00, 79.21batches/s, GPU_mem=0.0503G, loss=0.0842] \n",
      "Epoch 261/300: 100%|██████████| 469/469 [00:05<00:00, 79.41batches/s, GPU_mem=0.0503G, loss=0.0837] \n",
      "Epoch 262/300: 100%|██████████| 469/469 [00:05<00:00, 79.42batches/s, GPU_mem=0.0503G, loss=0.0843] \n",
      "Epoch 263/300: 100%|██████████| 469/469 [00:05<00:00, 78.33batches/s, GPU_mem=0.0503G, loss=0.0838] \n",
      "Epoch 264/300: 100%|██████████| 469/469 [00:05<00:00, 78.77batches/s, GPU_mem=0.0503G, loss=0.0831] \n",
      "Epoch 265/300: 100%|██████████| 469/469 [00:05<00:00, 80.88batches/s, GPU_mem=0.0503G, loss=0.0828] \n",
      "Epoch 266/300: 100%|██████████| 469/469 [00:05<00:00, 78.57batches/s, GPU_mem=0.0503G, loss=0.0827] \n",
      "Epoch 267/300: 100%|██████████| 469/469 [00:06<00:00, 77.30batches/s, GPU_mem=0.0503G, loss=0.0821] \n",
      "Epoch 268/300: 100%|██████████| 469/469 [00:06<00:00, 77.78batches/s, GPU_mem=0.0503G, loss=0.0822] \n",
      "Epoch 269/300: 100%|██████████| 469/469 [00:06<00:00, 77.81batches/s, GPU_mem=0.0503G, loss=0.0818] \n",
      "Epoch 270/300: 100%|██████████| 469/469 [00:05<00:00, 78.18batches/s, GPU_mem=0.0503G, loss=0.0821] \n",
      "Epoch 271/300: 100%|██████████| 469/469 [00:06<00:00, 77.94batches/s, GPU_mem=0.0503G, loss=0.0812] \n",
      "Epoch 272/300: 100%|██████████| 469/469 [00:05<00:00, 79.37batches/s, GPU_mem=0.0503G, loss=0.0806] \n",
      "Epoch 273/300: 100%|██████████| 469/469 [00:05<00:00, 79.41batches/s, GPU_mem=0.0503G, loss=0.0807] \n",
      "Epoch 274/300: 100%|██████████| 469/469 [00:05<00:00, 78.94batches/s, GPU_mem=0.0503G, loss=0.0807] \n",
      "Epoch 275/300: 100%|██████████| 469/469 [00:05<00:00, 79.39batches/s, GPU_mem=0.0503G, loss=0.0802] \n",
      "Epoch 276/300: 100%|██████████| 469/469 [00:05<00:00, 80.58batches/s, GPU_mem=0.0503G, loss=0.0802] \n",
      "Epoch 277/300: 100%|██████████| 469/469 [00:05<00:00, 78.59batches/s, GPU_mem=0.0503G, loss=0.0801] \n",
      "Epoch 278/300: 100%|██████████| 469/469 [00:05<00:00, 80.44batches/s, GPU_mem=0.0503G, loss=0.0793] \n",
      "Epoch 279/300: 100%|██████████| 469/469 [00:06<00:00, 77.79batches/s, GPU_mem=0.0503G, loss=0.0794] \n",
      "Epoch 280/300: 100%|██████████| 469/469 [00:06<00:00, 74.23batches/s, GPU_mem=0.0503G, loss=0.0791] \n",
      "Epoch 281/300: 100%|██████████| 469/469 [00:04<00:00, 106.74batches/s, GPU_mem=0.0503G, loss=0.0787]\n",
      "Epoch 282/300: 100%|██████████| 469/469 [00:04<00:00, 105.12batches/s, GPU_mem=0.0503G, loss=0.0784]\n",
      "Epoch 283/300: 100%|██████████| 469/469 [00:04<00:00, 106.08batches/s, GPU_mem=0.0503G, loss=0.0779]\n",
      "Epoch 284/300: 100%|██████████| 469/469 [00:04<00:00, 99.32batches/s, GPU_mem=0.0503G, loss=0.0779] \n",
      "Epoch 285/300: 100%|██████████| 469/469 [00:05<00:00, 81.92batches/s, GPU_mem=0.0503G, loss=0.0777] \n",
      "Epoch 286/300: 100%|██████████| 469/469 [00:06<00:00, 77.76batches/s, GPU_mem=0.0503G, loss=0.0778] \n",
      "Epoch 287/300: 100%|██████████| 469/469 [00:06<00:00, 73.97batches/s, GPU_mem=0.0503G, loss=0.0774] \n",
      "Epoch 288/300: 100%|██████████| 469/469 [00:06<00:00, 74.09batches/s, GPU_mem=0.0503G, loss=0.0775] \n",
      "Epoch 289/300: 100%|██████████| 469/469 [00:06<00:00, 75.48batches/s, GPU_mem=0.0503G, loss=0.0772] \n",
      "Epoch 290/300: 100%|██████████| 469/469 [00:06<00:00, 72.83batches/s, GPU_mem=0.0503G, loss=0.0767] \n",
      "Epoch 291/300: 100%|██████████| 469/469 [00:06<00:00, 76.11batches/s, GPU_mem=0.0503G, loss=0.0766] \n",
      "Epoch 292/300: 100%|██████████| 469/469 [00:06<00:00, 75.41batches/s, GPU_mem=0.0503G, loss=0.0763] \n",
      "Epoch 293/300: 100%|██████████| 469/469 [00:04<00:00, 100.49batches/s, GPU_mem=0.0503G, loss=0.0758]\n",
      "Epoch 294/300: 100%|██████████| 469/469 [00:04<00:00, 102.63batches/s, GPU_mem=0.0503G, loss=0.0757]\n",
      "Epoch 295/300: 100%|██████████| 469/469 [00:04<00:00, 107.08batches/s, GPU_mem=0.0503G, loss=0.0751]\n",
      "Epoch 296/300: 100%|██████████| 469/469 [00:04<00:00, 107.16batches/s, GPU_mem=0.0503G, loss=0.0752]\n",
      "Epoch 297/300: 100%|██████████| 469/469 [00:04<00:00, 106.12batches/s, GPU_mem=0.0503G, loss=0.0744]\n",
      "Epoch 298/300: 100%|██████████| 469/469 [00:04<00:00, 109.91batches/s, GPU_mem=0.0503G, loss=0.0745]\n",
      "Epoch 299/300: 100%|██████████| 469/469 [00:04<00:00, 107.59batches/s, GPU_mem=0.0503G, loss=0.0741]\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "for epoch in range(epochs):\n",
    "    train_model.train()\n",
    "    mloss = torch.zeros(1, device=device)  # mean_loss\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch}/{epochs}', unit='batches')\n",
    "\n",
    "    for i, (imgs, labels) in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        preds = train_model(imgs)\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        mloss = (mloss * i + loss) / (i + 1)\n",
    "        mem = f'{torch.cuda.memory_reserved() / 1e9 if torch.cuda.is_available() else 0:.3g}G'  # GPU_mem\n",
    "        pbar.set_postfix(loss=mloss.item(), GPU_mem=mem)\n",
    "\n",
    "    ckpt = {  # checkpoint\n",
    "        'epoch': epoch,\n",
    "        'model': deepcopy(train_model).half(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(ckpt, 'LeNet5.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T11:51:46.867014Z",
     "end_time": "2023-04-08T12:20:44.348155Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "LeNet5(\n  (backbone): Sequential(\n    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n    (1): Tanh()\n    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (3): Tanh()\n    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n    (5): Tanh()\n    (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (7): Tanh()\n    (8): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n    (9): Tanh()\n    (10): Flatten(start_dim=1, end_dim=-1)\n    (11): Linear(in_features=120, out_features=84, bias=True)\n    (12): Linear(in_features=84, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load('LeNet5.pt')\n",
    "test_model = ckpt['model'].to(device).float()\n",
    "test_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:20:44.349145Z",
     "end_time": "2023-04-08T12:20:44.390875Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='MNIST',\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=test_transform,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=128,\n",
    "    num_workers=4,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:20:44.364094Z",
     "end_time": "2023-04-08T12:20:44.398740Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 79/79 [00:02<00:00, 30.54batches/s]\n"
     ]
    }
   ],
   "source": [
    "correct = torch.zeros(1, device=device)\n",
    "total = torch.zeros(1, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc='Test', unit='batches')\n",
    "\n",
    "    for i, (imgs, labels) in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        preds = test_model(imgs)\n",
    "        preds = torch.argmax(nn.Softmax(dim=1)(preds), dim=1)  # 将预测结果经softmax后取最大值的序号为预测标签\n",
    "\n",
    "        total += torch.tensor(labels.size(0))\n",
    "        correct += (preds == labels).sum().item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:20:44.380259Z",
     "end_time": "2023-04-08T12:20:47.004458Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0.974"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = round((correct / total).item(), 3)\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:20:47.006508Z",
     "end_time": "2023-04-08T12:20:47.048868Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
