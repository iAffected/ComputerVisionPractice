{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-16T17:22:16.323254Z",
     "end_time": "2023-04-16T17:22:17.921290Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T17:22:17.922291Z",
     "end_time": "2023-04-16T17:22:17.955290Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_model = LeNet5().to(device)\n",
    "optimizer = torch.optim.Adam(params=train_model.parameters(), lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T17:22:17.955290Z",
     "end_time": "2023-04-16T17:22:18.108253Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='MNIST',\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=train_transform,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=128,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T17:22:18.110255Z",
     "end_time": "2023-04-16T17:22:18.172253Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/300: 100%|██████████| 469/469 [00:08<00:00, 58.52batches/s, GPU_mem=0.0503G, loss=2.28] \n",
      "Epoch 1/300: 100%|██████████| 469/469 [00:05<00:00, 86.98batches/s, GPU_mem=0.0503G, loss=2.11] \n",
      "Epoch 2/300: 100%|██████████| 469/469 [00:05<00:00, 92.52batches/s, GPU_mem=0.0503G, loss=1.72] \n",
      "Epoch 3/300: 100%|██████████| 469/469 [00:04<00:00, 94.56batches/s, GPU_mem=0.0503G, loss=1.37] \n",
      "Epoch 4/300: 100%|██████████| 469/469 [00:04<00:00, 93.91batches/s, GPU_mem=0.0503G, loss=1.17] \n",
      "Epoch 5/300: 100%|██████████| 469/469 [00:05<00:00, 86.92batches/s, GPU_mem=0.0503G, loss=1.05] \n",
      "Epoch 6/300: 100%|██████████| 469/469 [00:04<00:00, 98.90batches/s, GPU_mem=0.0503G, loss=0.96]  \n",
      "Epoch 7/300: 100%|██████████| 469/469 [00:04<00:00, 98.33batches/s, GPU_mem=0.0503G, loss=0.895] \n",
      "Epoch 8/300: 100%|██████████| 469/469 [00:05<00:00, 90.70batches/s, GPU_mem=0.0503G, loss=0.844] \n",
      "Epoch 9/300: 100%|██████████| 469/469 [00:04<00:00, 94.99batches/s, GPU_mem=0.0503G, loss=0.802] \n",
      "Epoch 10/300: 100%|██████████| 469/469 [00:04<00:00, 96.74batches/s, GPU_mem=0.0503G, loss=0.768] \n",
      "Epoch 11/300: 100%|██████████| 469/469 [00:05<00:00, 92.65batches/s, GPU_mem=0.0503G, loss=0.738] \n",
      "Epoch 12/300: 100%|██████████| 469/469 [00:05<00:00, 92.90batches/s, GPU_mem=0.0503G, loss=0.712] \n",
      "Epoch 13/300: 100%|██████████| 469/469 [00:04<00:00, 94.64batches/s, GPU_mem=0.0503G, loss=0.689] \n",
      "Epoch 14/300: 100%|██████████| 469/469 [00:04<00:00, 97.14batches/s, GPU_mem=0.0503G, loss=0.669] \n",
      "Epoch 15/300: 100%|██████████| 469/469 [00:04<00:00, 99.36batches/s, GPU_mem=0.0503G, loss=0.651] \n",
      "Epoch 16/300: 100%|██████████| 469/469 [00:04<00:00, 96.22batches/s, GPU_mem=0.0503G, loss=0.634] \n",
      "Epoch 17/300: 100%|██████████| 469/469 [00:04<00:00, 96.12batches/s, GPU_mem=0.0503G, loss=0.619] \n",
      "Epoch 18/300: 100%|██████████| 469/469 [00:05<00:00, 93.14batches/s, GPU_mem=0.0503G, loss=0.605] \n",
      "Epoch 19/300: 100%|██████████| 469/469 [00:05<00:00, 90.41batches/s, GPU_mem=0.0503G, loss=0.591] \n",
      "Epoch 20/300: 100%|██████████| 469/469 [00:04<00:00, 96.04batches/s, GPU_mem=0.0503G, loss=0.579] \n",
      "Epoch 21/300: 100%|██████████| 469/469 [00:04<00:00, 96.45batches/s, GPU_mem=0.0503G, loss=0.568] \n",
      "Epoch 22/300: 100%|██████████| 469/469 [00:05<00:00, 91.86batches/s, GPU_mem=0.0503G, loss=0.557] \n",
      "Epoch 23/300: 100%|██████████| 469/469 [00:05<00:00, 89.88batches/s, GPU_mem=0.0503G, loss=0.546] \n",
      "Epoch 24/300: 100%|██████████| 469/469 [00:05<00:00, 91.92batches/s, GPU_mem=0.0503G, loss=0.537] \n",
      "Epoch 25/300: 100%|██████████| 469/469 [00:05<00:00, 88.03batches/s, GPU_mem=0.0503G, loss=0.527] \n",
      "Epoch 26/300: 100%|██████████| 469/469 [00:05<00:00, 86.25batches/s, GPU_mem=0.0503G, loss=0.518] \n",
      "Epoch 27/300: 100%|██████████| 469/469 [00:06<00:00, 70.94batches/s, GPU_mem=0.0503G, loss=0.509] \n",
      "Epoch 28/300: 100%|██████████| 469/469 [00:06<00:00, 68.19batches/s, GPU_mem=0.0503G, loss=0.501] \n",
      "Epoch 29/300: 100%|██████████| 469/469 [00:07<00:00, 65.92batches/s, GPU_mem=0.0503G, loss=0.493] \n",
      "Epoch 30/300: 100%|██████████| 469/469 [00:06<00:00, 72.95batches/s, GPU_mem=0.0503G, loss=0.485] \n",
      "Epoch 31/300: 100%|██████████| 469/469 [00:06<00:00, 73.77batches/s, GPU_mem=0.0503G, loss=0.478] \n",
      "Epoch 32/300: 100%|██████████| 469/469 [00:06<00:00, 69.84batches/s, GPU_mem=0.0503G, loss=0.471] \n",
      "Epoch 33/300: 100%|██████████| 469/469 [00:06<00:00, 73.39batches/s, GPU_mem=0.0503G, loss=0.463] \n",
      "Epoch 34/300: 100%|██████████| 469/469 [00:06<00:00, 72.99batches/s, GPU_mem=0.0503G, loss=0.456] \n",
      "Epoch 35/300: 100%|██████████| 469/469 [00:06<00:00, 73.50batches/s, GPU_mem=0.0503G, loss=0.45]  \n",
      "Epoch 36/300: 100%|██████████| 469/469 [00:06<00:00, 70.31batches/s, GPU_mem=0.0503G, loss=0.443] \n",
      "Epoch 37/300: 100%|██████████| 469/469 [00:06<00:00, 74.41batches/s, GPU_mem=0.0503G, loss=0.437] \n",
      "Epoch 38/300: 100%|██████████| 469/469 [00:06<00:00, 72.05batches/s, GPU_mem=0.0503G, loss=0.431] \n",
      "Epoch 39/300: 100%|██████████| 469/469 [00:06<00:00, 68.97batches/s, GPU_mem=0.0503G, loss=0.425] \n",
      "Epoch 40/300: 100%|██████████| 469/469 [00:06<00:00, 69.01batches/s, GPU_mem=0.0503G, loss=0.419] \n",
      "Epoch 41/300: 100%|██████████| 469/469 [00:06<00:00, 71.50batches/s, GPU_mem=0.0503G, loss=0.413] \n",
      "Epoch 42/300: 100%|██████████| 469/469 [00:06<00:00, 70.39batches/s, GPU_mem=0.0503G, loss=0.407] \n",
      "Epoch 43/300: 100%|██████████| 469/469 [00:06<00:00, 70.95batches/s, GPU_mem=0.0503G, loss=0.402] \n",
      "Epoch 44/300: 100%|██████████| 469/469 [00:07<00:00, 66.86batches/s, GPU_mem=0.0503G, loss=0.396] \n",
      "Epoch 45/300: 100%|██████████| 469/469 [00:05<00:00, 93.49batches/s, GPU_mem=0.0503G, loss=0.391] \n",
      "Epoch 46/300: 100%|██████████| 469/469 [00:04<00:00, 94.56batches/s, GPU_mem=0.0503G, loss=0.385] \n",
      "Epoch 47/300: 100%|██████████| 469/469 [00:04<00:00, 94.39batches/s, GPU_mem=0.0503G, loss=0.381] \n",
      "Epoch 48/300: 100%|██████████| 469/469 [00:04<00:00, 95.70batches/s, GPU_mem=0.0503G, loss=0.375] \n",
      "Epoch 49/300: 100%|██████████| 469/469 [00:04<00:00, 95.35batches/s, GPU_mem=0.0503G, loss=0.37]  \n",
      "Epoch 50/300: 100%|██████████| 469/469 [00:05<00:00, 92.27batches/s, GPU_mem=0.0503G, loss=0.366] \n",
      "Epoch 51/300: 100%|██████████| 469/469 [00:05<00:00, 92.83batches/s, GPU_mem=0.0503G, loss=0.361] \n",
      "Epoch 52/300: 100%|██████████| 469/469 [00:04<00:00, 97.80batches/s, GPU_mem=0.0503G, loss=0.357] \n",
      "Epoch 53/300: 100%|██████████| 469/469 [00:06<00:00, 73.98batches/s, GPU_mem=0.0503G, loss=0.352] \n",
      "Epoch 54/300: 100%|██████████| 469/469 [00:06<00:00, 69.13batches/s, GPU_mem=0.0503G, loss=0.347] \n",
      "Epoch 55/300: 100%|██████████| 469/469 [00:06<00:00, 70.96batches/s, GPU_mem=0.0503G, loss=0.344] \n",
      "Epoch 56/300: 100%|██████████| 469/469 [00:06<00:00, 71.16batches/s, GPU_mem=0.0503G, loss=0.34]  \n",
      "Epoch 57/300: 100%|██████████| 469/469 [00:06<00:00, 72.84batches/s, GPU_mem=0.0503G, loss=0.335] \n",
      "Epoch 58/300: 100%|██████████| 469/469 [00:06<00:00, 78.10batches/s, GPU_mem=0.0503G, loss=0.331] \n",
      "Epoch 59/300: 100%|██████████| 469/469 [00:06<00:00, 74.55batches/s, GPU_mem=0.0503G, loss=0.327] \n",
      "Epoch 60/300: 100%|██████████| 469/469 [00:06<00:00, 74.49batches/s, GPU_mem=0.0503G, loss=0.323] \n",
      "Epoch 61/300: 100%|██████████| 469/469 [00:06<00:00, 74.36batches/s, GPU_mem=0.0503G, loss=0.319] \n",
      "Epoch 62/300: 100%|██████████| 469/469 [00:06<00:00, 72.79batches/s, GPU_mem=0.0503G, loss=0.315] \n",
      "Epoch 63/300: 100%|██████████| 469/469 [00:06<00:00, 72.28batches/s, GPU_mem=0.0503G, loss=0.312] \n",
      "Epoch 64/300: 100%|██████████| 469/469 [00:04<00:00, 102.48batches/s, GPU_mem=0.0503G, loss=0.308]\n",
      "Epoch 65/300: 100%|██████████| 469/469 [00:04<00:00, 102.75batches/s, GPU_mem=0.0503G, loss=0.305]\n",
      "Epoch 66/300: 100%|██████████| 469/469 [00:04<00:00, 100.59batches/s, GPU_mem=0.0503G, loss=0.302]\n",
      "Epoch 67/300: 100%|██████████| 469/469 [00:04<00:00, 101.51batches/s, GPU_mem=0.0503G, loss=0.298]\n",
      "Epoch 68/300: 100%|██████████| 469/469 [00:04<00:00, 100.97batches/s, GPU_mem=0.0503G, loss=0.295]\n",
      "Epoch 69/300: 100%|██████████| 469/469 [00:04<00:00, 101.02batches/s, GPU_mem=0.0503G, loss=0.291]\n",
      "Epoch 70/300: 100%|██████████| 469/469 [00:04<00:00, 102.12batches/s, GPU_mem=0.0503G, loss=0.288]\n",
      "Epoch 71/300: 100%|██████████| 469/469 [00:04<00:00, 102.53batches/s, GPU_mem=0.0503G, loss=0.285]\n",
      "Epoch 72/300: 100%|██████████| 469/469 [00:04<00:00, 101.16batches/s, GPU_mem=0.0503G, loss=0.282]\n",
      "Epoch 73/300: 100%|██████████| 469/469 [00:04<00:00, 100.26batches/s, GPU_mem=0.0503G, loss=0.279]\n",
      "Epoch 74/300: 100%|██████████| 469/469 [00:04<00:00, 101.24batches/s, GPU_mem=0.0503G, loss=0.277]\n",
      "Epoch 75/300: 100%|██████████| 469/469 [00:04<00:00, 101.61batches/s, GPU_mem=0.0503G, loss=0.274]\n",
      "Epoch 76/300: 100%|██████████| 469/469 [00:04<00:00, 100.94batches/s, GPU_mem=0.0503G, loss=0.271]\n",
      "Epoch 77/300: 100%|██████████| 469/469 [00:04<00:00, 101.31batches/s, GPU_mem=0.0503G, loss=0.268]\n",
      "Epoch 78/300: 100%|██████████| 469/469 [00:04<00:00, 100.89batches/s, GPU_mem=0.0503G, loss=0.266]\n",
      "Epoch 79/300: 100%|██████████| 469/469 [00:04<00:00, 99.11batches/s, GPU_mem=0.0503G, loss=0.263] \n",
      "Epoch 80/300: 100%|██████████| 469/469 [00:04<00:00, 99.96batches/s, GPU_mem=0.0503G, loss=0.26]  \n",
      "Epoch 81/300: 100%|██████████| 469/469 [00:04<00:00, 99.60batches/s, GPU_mem=0.0503G, loss=0.257] \n",
      "Epoch 82/300: 100%|██████████| 469/469 [00:04<00:00, 102.86batches/s, GPU_mem=0.0503G, loss=0.255]\n",
      "Epoch 83/300: 100%|██████████| 469/469 [00:04<00:00, 100.58batches/s, GPU_mem=0.0503G, loss=0.253]\n",
      "Epoch 84/300: 100%|██████████| 469/469 [00:04<00:00, 99.55batches/s, GPU_mem=0.0503G, loss=0.251] \n",
      "Epoch 85/300: 100%|██████████| 469/469 [00:04<00:00, 101.37batches/s, GPU_mem=0.0503G, loss=0.248]\n",
      "Epoch 86/300: 100%|██████████| 469/469 [00:04<00:00, 100.45batches/s, GPU_mem=0.0503G, loss=0.246]\n",
      "Epoch 87/300: 100%|██████████| 469/469 [00:04<00:00, 102.40batches/s, GPU_mem=0.0503G, loss=0.243]\n",
      "Epoch 88/300: 100%|██████████| 469/469 [00:04<00:00, 100.55batches/s, GPU_mem=0.0503G, loss=0.241]\n",
      "Epoch 89/300: 100%|██████████| 469/469 [00:04<00:00, 102.56batches/s, GPU_mem=0.0503G, loss=0.239]\n",
      "Epoch 90/300: 100%|██████████| 469/469 [00:04<00:00, 100.23batches/s, GPU_mem=0.0503G, loss=0.237]\n",
      "Epoch 91/300: 100%|██████████| 469/469 [00:04<00:00, 102.08batches/s, GPU_mem=0.0503G, loss=0.234]\n",
      "Epoch 92/300: 100%|██████████| 469/469 [00:04<00:00, 101.56batches/s, GPU_mem=0.0503G, loss=0.233]\n",
      "Epoch 93/300: 100%|██████████| 469/469 [00:04<00:00, 100.92batches/s, GPU_mem=0.0503G, loss=0.23] \n",
      "Epoch 94/300: 100%|██████████| 469/469 [00:04<00:00, 101.39batches/s, GPU_mem=0.0503G, loss=0.229]\n",
      "Epoch 95/300: 100%|██████████| 469/469 [00:04<00:00, 101.90batches/s, GPU_mem=0.0503G, loss=0.227]\n",
      "Epoch 96/300: 100%|██████████| 469/469 [00:04<00:00, 98.75batches/s, GPU_mem=0.0503G, loss=0.225] \n",
      "Epoch 97/300: 100%|██████████| 469/469 [00:04<00:00, 100.60batches/s, GPU_mem=0.0503G, loss=0.223]\n",
      "Epoch 98/300: 100%|██████████| 469/469 [00:04<00:00, 100.14batches/s, GPU_mem=0.0503G, loss=0.221]\n",
      "Epoch 99/300: 100%|██████████| 469/469 [00:04<00:00, 100.86batches/s, GPU_mem=0.0503G, loss=0.219]\n",
      "Epoch 100/300: 100%|██████████| 469/469 [00:04<00:00, 100.77batches/s, GPU_mem=0.0503G, loss=0.218]\n",
      "Epoch 101/300: 100%|██████████| 469/469 [00:04<00:00, 100.13batches/s, GPU_mem=0.0503G, loss=0.215]\n",
      "Epoch 102/300: 100%|██████████| 469/469 [00:04<00:00, 100.54batches/s, GPU_mem=0.0503G, loss=0.214]\n",
      "Epoch 103/300: 100%|██████████| 469/469 [00:04<00:00, 101.96batches/s, GPU_mem=0.0503G, loss=0.212]\n",
      "Epoch 104/300: 100%|██████████| 469/469 [00:04<00:00, 98.28batches/s, GPU_mem=0.0503G, loss=0.21]  \n",
      "Epoch 105/300: 100%|██████████| 469/469 [00:04<00:00, 98.23batches/s, GPU_mem=0.0503G, loss=0.209] \n",
      "Epoch 106/300: 100%|██████████| 469/469 [00:04<00:00, 99.30batches/s, GPU_mem=0.0503G, loss=0.207] \n",
      "Epoch 107/300: 100%|██████████| 469/469 [00:04<00:00, 101.55batches/s, GPU_mem=0.0503G, loss=0.205]\n",
      "Epoch 108/300: 100%|██████████| 469/469 [00:04<00:00, 101.81batches/s, GPU_mem=0.0503G, loss=0.204]\n",
      "Epoch 109/300: 100%|██████████| 469/469 [00:04<00:00, 100.92batches/s, GPU_mem=0.0503G, loss=0.202]\n",
      "Epoch 110/300: 100%|██████████| 469/469 [00:04<00:00, 100.46batches/s, GPU_mem=0.0503G, loss=0.2]  \n",
      "Epoch 111/300: 100%|██████████| 469/469 [00:04<00:00, 97.24batches/s, GPU_mem=0.0503G, loss=0.199] \n",
      "Epoch 112/300: 100%|██████████| 469/469 [00:06<00:00, 74.22batches/s, GPU_mem=0.0503G, loss=0.197] \n",
      "Epoch 113/300: 100%|██████████| 469/469 [00:06<00:00, 72.57batches/s, GPU_mem=0.0503G, loss=0.196] \n",
      "Epoch 114/300: 100%|██████████| 469/469 [00:06<00:00, 74.37batches/s, GPU_mem=0.0503G, loss=0.194] \n",
      "Epoch 115/300: 100%|██████████| 469/469 [00:05<00:00, 78.74batches/s, GPU_mem=0.0503G, loss=0.193] \n",
      "Epoch 116/300: 100%|██████████| 469/469 [00:06<00:00, 76.86batches/s, GPU_mem=0.0503G, loss=0.191] \n",
      "Epoch 117/300: 100%|██████████| 469/469 [00:06<00:00, 73.50batches/s, GPU_mem=0.0503G, loss=0.19]  \n",
      "Epoch 118/300: 100%|██████████| 469/469 [00:06<00:00, 76.42batches/s, GPU_mem=0.0503G, loss=0.188] \n",
      "Epoch 119/300: 100%|██████████| 469/469 [00:05<00:00, 80.89batches/s, GPU_mem=0.0503G, loss=0.187] \n",
      "Epoch 120/300: 100%|██████████| 469/469 [00:06<00:00, 77.92batches/s, GPU_mem=0.0503G, loss=0.186] \n",
      "Epoch 121/300: 100%|██████████| 469/469 [00:06<00:00, 76.11batches/s, GPU_mem=0.0503G, loss=0.185] \n",
      "Epoch 122/300: 100%|██████████| 469/469 [00:05<00:00, 78.56batches/s, GPU_mem=0.0503G, loss=0.183] \n",
      "Epoch 123/300: 100%|██████████| 469/469 [00:06<00:00, 75.15batches/s, GPU_mem=0.0503G, loss=0.182] \n",
      "Epoch 124/300: 100%|██████████| 469/469 [00:06<00:00, 77.49batches/s, GPU_mem=0.0503G, loss=0.181] \n",
      "Epoch 125/300: 100%|██████████| 469/469 [00:06<00:00, 74.49batches/s, GPU_mem=0.0503G, loss=0.179] \n",
      "Epoch 126/300: 100%|██████████| 469/469 [00:06<00:00, 77.28batches/s, GPU_mem=0.0503G, loss=0.178] \n",
      "Epoch 127/300: 100%|██████████| 469/469 [00:06<00:00, 76.10batches/s, GPU_mem=0.0503G, loss=0.177] \n",
      "Epoch 128/300: 100%|██████████| 469/469 [00:06<00:00, 74.92batches/s, GPU_mem=0.0503G, loss=0.176] \n",
      "Epoch 129/300: 100%|██████████| 469/469 [00:06<00:00, 75.46batches/s, GPU_mem=0.0503G, loss=0.174] \n",
      "Epoch 130/300: 100%|██████████| 469/469 [00:06<00:00, 76.61batches/s, GPU_mem=0.0503G, loss=0.173] \n",
      "Epoch 131/300: 100%|██████████| 469/469 [00:06<00:00, 76.34batches/s, GPU_mem=0.0503G, loss=0.172] \n",
      "Epoch 132/300: 100%|██████████| 469/469 [00:05<00:00, 79.43batches/s, GPU_mem=0.0503G, loss=0.171] \n",
      "Epoch 133/300: 100%|██████████| 469/469 [00:05<00:00, 78.18batches/s, GPU_mem=0.0503G, loss=0.17]  \n",
      "Epoch 134/300: 100%|██████████| 469/469 [00:06<00:00, 77.92batches/s, GPU_mem=0.0503G, loss=0.169] \n",
      "Epoch 135/300: 100%|██████████| 469/469 [00:05<00:00, 78.33batches/s, GPU_mem=0.0503G, loss=0.168] \n",
      "Epoch 136/300: 100%|██████████| 469/469 [00:05<00:00, 79.09batches/s, GPU_mem=0.0503G, loss=0.166] \n",
      "Epoch 137/300: 100%|██████████| 469/469 [00:06<00:00, 76.98batches/s, GPU_mem=0.0503G, loss=0.165] \n",
      "Epoch 138/300: 100%|██████████| 469/469 [00:06<00:00, 77.95batches/s, GPU_mem=0.0503G, loss=0.165] \n",
      "Epoch 139/300: 100%|██████████| 469/469 [00:06<00:00, 77.69batches/s, GPU_mem=0.0503G, loss=0.163] \n",
      "Epoch 140/300: 100%|██████████| 469/469 [00:06<00:00, 77.69batches/s, GPU_mem=0.0503G, loss=0.162] \n",
      "Epoch 141/300: 100%|██████████| 469/469 [00:05<00:00, 78.34batches/s, GPU_mem=0.0503G, loss=0.161] \n",
      "Epoch 142/300: 100%|██████████| 469/469 [00:05<00:00, 79.11batches/s, GPU_mem=0.0503G, loss=0.161] \n",
      "Epoch 143/300: 100%|██████████| 469/469 [00:05<00:00, 79.04batches/s, GPU_mem=0.0503G, loss=0.159] \n",
      "Epoch 144/300: 100%|██████████| 469/469 [00:05<00:00, 78.54batches/s, GPU_mem=0.0503G, loss=0.158] \n",
      "Epoch 145/300: 100%|██████████| 469/469 [00:06<00:00, 77.44batches/s, GPU_mem=0.0503G, loss=0.158] \n",
      "Epoch 146/300: 100%|██████████| 469/469 [00:05<00:00, 78.77batches/s, GPU_mem=0.0503G, loss=0.156] \n",
      "Epoch 147/300: 100%|██████████| 469/469 [00:05<00:00, 79.04batches/s, GPU_mem=0.0503G, loss=0.155] \n",
      "Epoch 148/300: 100%|██████████| 469/469 [00:06<00:00, 77.84batches/s, GPU_mem=0.0503G, loss=0.154] \n",
      "Epoch 149/300: 100%|██████████| 469/469 [00:06<00:00, 75.97batches/s, GPU_mem=0.0503G, loss=0.154] \n",
      "Epoch 150/300: 100%|██████████| 469/469 [00:05<00:00, 78.88batches/s, GPU_mem=0.0503G, loss=0.152] \n",
      "Epoch 151/300: 100%|██████████| 469/469 [00:05<00:00, 78.71batches/s, GPU_mem=0.0503G, loss=0.152] \n",
      "Epoch 152/300: 100%|██████████| 469/469 [00:05<00:00, 79.19batches/s, GPU_mem=0.0503G, loss=0.151] \n",
      "Epoch 153/300: 100%|██████████| 469/469 [00:05<00:00, 78.42batches/s, GPU_mem=0.0503G, loss=0.15]  \n",
      "Epoch 154/300: 100%|██████████| 469/469 [00:05<00:00, 78.32batches/s, GPU_mem=0.0503G, loss=0.149] \n",
      "Epoch 155/300: 100%|██████████| 469/469 [00:06<00:00, 77.76batches/s, GPU_mem=0.0503G, loss=0.148] \n",
      "Epoch 156/300: 100%|██████████| 469/469 [00:06<00:00, 77.38batches/s, GPU_mem=0.0503G, loss=0.147] \n",
      "Epoch 157/300: 100%|██████████| 469/469 [00:06<00:00, 77.77batches/s, GPU_mem=0.0503G, loss=0.146] \n",
      "Epoch 158/300: 100%|██████████| 469/469 [00:06<00:00, 77.66batches/s, GPU_mem=0.0503G, loss=0.145] \n",
      "Epoch 159/300: 100%|██████████| 469/469 [00:06<00:00, 75.51batches/s, GPU_mem=0.0503G, loss=0.145] \n",
      "Epoch 160/300: 100%|██████████| 469/469 [00:06<00:00, 76.58batches/s, GPU_mem=0.0503G, loss=0.143] \n",
      "Epoch 161/300: 100%|██████████| 469/469 [00:05<00:00, 79.77batches/s, GPU_mem=0.0503G, loss=0.143] \n",
      "Epoch 162/300: 100%|██████████| 469/469 [00:06<00:00, 76.71batches/s, GPU_mem=0.0503G, loss=0.143] \n",
      "Epoch 163/300: 100%|██████████| 469/469 [00:06<00:00, 77.30batches/s, GPU_mem=0.0503G, loss=0.142] \n",
      "Epoch 164/300: 100%|██████████| 469/469 [00:06<00:00, 77.72batches/s, GPU_mem=0.0503G, loss=0.141] \n",
      "Epoch 165/300: 100%|██████████| 469/469 [00:06<00:00, 77.03batches/s, GPU_mem=0.0503G, loss=0.141] \n",
      "Epoch 166/300: 100%|██████████| 469/469 [00:06<00:00, 76.41batches/s, GPU_mem=0.0503G, loss=0.139] \n",
      "Epoch 167/300: 100%|██████████| 469/469 [00:05<00:00, 79.10batches/s, GPU_mem=0.0503G, loss=0.139] \n",
      "Epoch 168/300: 100%|██████████| 469/469 [00:05<00:00, 78.48batches/s, GPU_mem=0.0503G, loss=0.138] \n",
      "Epoch 169/300: 100%|██████████| 469/469 [00:05<00:00, 79.69batches/s, GPU_mem=0.0503G, loss=0.137] \n",
      "Epoch 170/300: 100%|██████████| 469/469 [00:06<00:00, 78.11batches/s, GPU_mem=0.0503G, loss=0.137] \n",
      "Epoch 171/300: 100%|██████████| 469/469 [00:05<00:00, 80.56batches/s, GPU_mem=0.0503G, loss=0.136] \n",
      "Epoch 172/300: 100%|██████████| 469/469 [00:05<00:00, 78.79batches/s, GPU_mem=0.0503G, loss=0.135] \n",
      "Epoch 173/300: 100%|██████████| 469/469 [00:05<00:00, 79.68batches/s, GPU_mem=0.0503G, loss=0.134] \n",
      "Epoch 174/300: 100%|██████████| 469/469 [00:05<00:00, 78.86batches/s, GPU_mem=0.0503G, loss=0.133] \n",
      "Epoch 175/300: 100%|██████████| 469/469 [00:05<00:00, 78.45batches/s, GPU_mem=0.0503G, loss=0.133] \n",
      "Epoch 176/300: 100%|██████████| 469/469 [00:05<00:00, 80.21batches/s, GPU_mem=0.0503G, loss=0.132] \n",
      "Epoch 177/300: 100%|██████████| 469/469 [00:05<00:00, 78.44batches/s, GPU_mem=0.0503G, loss=0.131] \n",
      "Epoch 178/300: 100%|██████████| 469/469 [00:05<00:00, 78.35batches/s, GPU_mem=0.0503G, loss=0.131] \n",
      "Epoch 179/300: 100%|██████████| 469/469 [00:06<00:00, 78.09batches/s, GPU_mem=0.0503G, loss=0.13]  \n",
      "Epoch 180/300: 100%|██████████| 469/469 [00:06<00:00, 77.26batches/s, GPU_mem=0.0503G, loss=0.129] \n",
      "Epoch 181/300: 100%|██████████| 469/469 [00:05<00:00, 78.32batches/s, GPU_mem=0.0503G, loss=0.13]  \n",
      "Epoch 182/300: 100%|██████████| 469/469 [00:06<00:00, 77.78batches/s, GPU_mem=0.0503G, loss=0.129] \n",
      "Epoch 183/300: 100%|██████████| 469/469 [00:06<00:00, 77.74batches/s, GPU_mem=0.0503G, loss=0.128] \n",
      "Epoch 184/300: 100%|██████████| 469/469 [00:06<00:00, 76.92batches/s, GPU_mem=0.0503G, loss=0.127] \n",
      "Epoch 185/300: 100%|██████████| 469/469 [00:05<00:00, 79.53batches/s, GPU_mem=0.0503G, loss=0.127] \n",
      "Epoch 186/300: 100%|██████████| 469/469 [00:05<00:00, 79.23batches/s, GPU_mem=0.0503G, loss=0.125] \n",
      "Epoch 187/300: 100%|██████████| 469/469 [00:06<00:00, 76.93batches/s, GPU_mem=0.0503G, loss=0.126] \n",
      "Epoch 188/300: 100%|██████████| 469/469 [00:06<00:00, 75.20batches/s, GPU_mem=0.0503G, loss=0.124] \n",
      "Epoch 189/300: 100%|██████████| 469/469 [00:06<00:00, 74.96batches/s, GPU_mem=0.0503G, loss=0.124] \n",
      "Epoch 190/300: 100%|██████████| 469/469 [00:06<00:00, 74.49batches/s, GPU_mem=0.0503G, loss=0.124] \n",
      "Epoch 191/300: 100%|██████████| 469/469 [00:06<00:00, 74.35batches/s, GPU_mem=0.0503G, loss=0.124] \n",
      "Epoch 192/300: 100%|██████████| 469/469 [00:06<00:00, 76.93batches/s, GPU_mem=0.0503G, loss=0.122] \n",
      "Epoch 193/300: 100%|██████████| 469/469 [00:06<00:00, 77.81batches/s, GPU_mem=0.0503G, loss=0.121] \n",
      "Epoch 194/300: 100%|██████████| 469/469 [00:06<00:00, 76.42batches/s, GPU_mem=0.0503G, loss=0.121] \n",
      "Epoch 195/300: 100%|██████████| 469/469 [00:05<00:00, 78.63batches/s, GPU_mem=0.0503G, loss=0.121] \n",
      "Epoch 196/300: 100%|██████████| 469/469 [00:06<00:00, 78.07batches/s, GPU_mem=0.0503G, loss=0.12]  \n",
      "Epoch 197/300: 100%|██████████| 469/469 [00:06<00:00, 77.60batches/s, GPU_mem=0.0503G, loss=0.12]  \n",
      "Epoch 198/300: 100%|██████████| 469/469 [00:06<00:00, 76.99batches/s, GPU_mem=0.0503G, loss=0.119] \n",
      "Epoch 199/300: 100%|██████████| 469/469 [00:06<00:00, 76.84batches/s, GPU_mem=0.0503G, loss=0.119] \n",
      "Epoch 200/300: 100%|██████████| 469/469 [00:05<00:00, 79.62batches/s, GPU_mem=0.0503G, loss=0.118] \n",
      "Epoch 201/300: 100%|██████████| 469/469 [00:06<00:00, 75.66batches/s, GPU_mem=0.0503G, loss=0.118] \n",
      "Epoch 202/300: 100%|██████████| 469/469 [00:06<00:00, 76.24batches/s, GPU_mem=0.0503G, loss=0.117] \n",
      "Epoch 203/300: 100%|██████████| 469/469 [00:05<00:00, 78.59batches/s, GPU_mem=0.0503G, loss=0.117] \n",
      "Epoch 204/300: 100%|██████████| 469/469 [00:06<00:00, 77.01batches/s, GPU_mem=0.0503G, loss=0.117] \n",
      "Epoch 205/300: 100%|██████████| 469/469 [00:06<00:00, 78.14batches/s, GPU_mem=0.0503G, loss=0.116] \n",
      "Epoch 206/300: 100%|██████████| 469/469 [00:05<00:00, 78.40batches/s, GPU_mem=0.0503G, loss=0.115] \n",
      "Epoch 207/300: 100%|██████████| 469/469 [00:06<00:00, 77.83batches/s, GPU_mem=0.0503G, loss=0.114] \n",
      "Epoch 208/300: 100%|██████████| 469/469 [00:05<00:00, 78.38batches/s, GPU_mem=0.0503G, loss=0.114] \n",
      "Epoch 209/300: 100%|██████████| 469/469 [00:05<00:00, 78.94batches/s, GPU_mem=0.0503G, loss=0.114] \n",
      "Epoch 210/300: 100%|██████████| 469/469 [00:06<00:00, 76.73batches/s, GPU_mem=0.0503G, loss=0.114] \n",
      "Epoch 211/300: 100%|██████████| 469/469 [00:06<00:00, 77.46batches/s, GPU_mem=0.0503G, loss=0.113] \n",
      "Epoch 212/300: 100%|██████████| 469/469 [00:05<00:00, 78.56batches/s, GPU_mem=0.0503G, loss=0.112] \n",
      "Epoch 213/300: 100%|██████████| 469/469 [00:06<00:00, 77.34batches/s, GPU_mem=0.0503G, loss=0.111] \n",
      "Epoch 214/300: 100%|██████████| 469/469 [00:06<00:00, 77.24batches/s, GPU_mem=0.0503G, loss=0.112] \n",
      "Epoch 215/300: 100%|██████████| 469/469 [00:06<00:00, 78.15batches/s, GPU_mem=0.0503G, loss=0.111] \n",
      "Epoch 216/300: 100%|██████████| 469/469 [00:06<00:00, 76.44batches/s, GPU_mem=0.0503G, loss=0.11]  \n",
      "Epoch 217/300: 100%|██████████| 469/469 [00:06<00:00, 77.72batches/s, GPU_mem=0.0503G, loss=0.109] \n",
      "Epoch 218/300: 100%|██████████| 469/469 [00:06<00:00, 77.72batches/s, GPU_mem=0.0503G, loss=0.109] \n",
      "Epoch 219/300: 100%|██████████| 469/469 [00:06<00:00, 77.18batches/s, GPU_mem=0.0503G, loss=0.108] \n",
      "Epoch 220/300: 100%|██████████| 469/469 [00:06<00:00, 77.99batches/s, GPU_mem=0.0503G, loss=0.108] \n",
      "Epoch 221/300: 100%|██████████| 469/469 [00:06<00:00, 74.75batches/s, GPU_mem=0.0503G, loss=0.107] \n",
      "Epoch 222/300: 100%|██████████| 469/469 [00:06<00:00, 76.02batches/s, GPU_mem=0.0503G, loss=0.107] \n",
      "Epoch 223/300: 100%|██████████| 469/469 [00:05<00:00, 78.82batches/s, GPU_mem=0.0503G, loss=0.107] \n",
      "Epoch 224/300: 100%|██████████| 469/469 [00:05<00:00, 79.29batches/s, GPU_mem=0.0503G, loss=0.106] \n",
      "Epoch 225/300: 100%|██████████| 469/469 [00:05<00:00, 78.64batches/s, GPU_mem=0.0503G, loss=0.106] \n",
      "Epoch 226/300: 100%|██████████| 469/469 [00:05<00:00, 79.57batches/s, GPU_mem=0.0503G, loss=0.106] \n",
      "Epoch 227/300: 100%|██████████| 469/469 [00:06<00:00, 76.70batches/s, GPU_mem=0.0503G, loss=0.106] \n",
      "Epoch 228/300: 100%|██████████| 469/469 [00:05<00:00, 79.05batches/s, GPU_mem=0.0503G, loss=0.105] \n",
      "Epoch 229/300: 100%|██████████| 469/469 [00:05<00:00, 78.71batches/s, GPU_mem=0.0503G, loss=0.105] \n",
      "Epoch 230/300: 100%|██████████| 469/469 [00:05<00:00, 79.85batches/s, GPU_mem=0.0503G, loss=0.104] \n",
      "Epoch 231/300: 100%|██████████| 469/469 [00:06<00:00, 77.19batches/s, GPU_mem=0.0503G, loss=0.103]  \n",
      "Epoch 232/300: 100%|██████████| 469/469 [00:06<00:00, 77.76batches/s, GPU_mem=0.0503G, loss=0.103] \n",
      "Epoch 233/300: 100%|██████████| 469/469 [00:06<00:00, 76.69batches/s, GPU_mem=0.0503G, loss=0.103] \n",
      "Epoch 234/300: 100%|██████████| 469/469 [00:05<00:00, 79.44batches/s, GPU_mem=0.0503G, loss=0.102]  \n",
      "Epoch 235/300: 100%|██████████| 469/469 [00:05<00:00, 78.57batches/s, GPU_mem=0.0503G, loss=0.102]  \n",
      "Epoch 236/300: 100%|██████████| 469/469 [00:05<00:00, 78.81batches/s, GPU_mem=0.0503G, loss=0.102]  \n",
      "Epoch 237/300: 100%|██████████| 469/469 [00:06<00:00, 77.04batches/s, GPU_mem=0.0503G, loss=0.101]  \n",
      "Epoch 238/300: 100%|██████████| 469/469 [00:06<00:00, 75.56batches/s, GPU_mem=0.0503G, loss=0.1]    \n",
      "Epoch 239/300: 100%|██████████| 469/469 [00:05<00:00, 78.30batches/s, GPU_mem=0.0503G, loss=0.101]  \n",
      "Epoch 240/300: 100%|██████████| 469/469 [00:06<00:00, 78.05batches/s, GPU_mem=0.0503G, loss=0.101]  \n",
      "Epoch 241/300: 100%|██████████| 469/469 [00:05<00:00, 79.84batches/s, GPU_mem=0.0503G, loss=0.1]   \n",
      "Epoch 242/300: 100%|██████████| 469/469 [00:05<00:00, 78.27batches/s, GPU_mem=0.0503G, loss=0.0992] \n",
      "Epoch 243/300: 100%|██████████| 469/469 [00:06<00:00, 76.45batches/s, GPU_mem=0.0503G, loss=0.0993] \n",
      "Epoch 244/300: 100%|██████████| 469/469 [00:06<00:00, 76.03batches/s, GPU_mem=0.0503G, loss=0.0987] \n",
      "Epoch 245/300: 100%|██████████| 469/469 [00:06<00:00, 76.67batches/s, GPU_mem=0.0503G, loss=0.0982] \n",
      "Epoch 246/300: 100%|██████████| 469/469 [00:06<00:00, 75.89batches/s, GPU_mem=0.0503G, loss=0.098]  \n",
      "Epoch 247/300: 100%|██████████| 469/469 [00:06<00:00, 76.51batches/s, GPU_mem=0.0503G, loss=0.0972] \n",
      "Epoch 248/300: 100%|██████████| 469/469 [00:06<00:00, 76.88batches/s, GPU_mem=0.0503G, loss=0.0981] \n",
      "Epoch 249/300: 100%|██████████| 469/469 [00:06<00:00, 74.06batches/s, GPU_mem=0.0503G, loss=0.0964] \n",
      "Epoch 250/300: 100%|██████████| 469/469 [00:06<00:00, 75.76batches/s, GPU_mem=0.0503G, loss=0.0965] \n",
      "Epoch 251/300: 100%|██████████| 469/469 [00:06<00:00, 76.87batches/s, GPU_mem=0.0503G, loss=0.0963] \n",
      "Epoch 252/300: 100%|██████████| 469/469 [00:05<00:00, 79.45batches/s, GPU_mem=0.0503G, loss=0.0955] \n",
      "Epoch 253/300: 100%|██████████| 469/469 [00:06<00:00, 77.50batches/s, GPU_mem=0.0503G, loss=0.0949] \n",
      "Epoch 254/300: 100%|██████████| 469/469 [00:06<00:00, 75.70batches/s, GPU_mem=0.0503G, loss=0.0954] \n",
      "Epoch 255/300: 100%|██████████| 469/469 [00:06<00:00, 76.51batches/s, GPU_mem=0.0503G, loss=0.0949] \n",
      "Epoch 256/300: 100%|██████████| 469/469 [00:06<00:00, 76.78batches/s, GPU_mem=0.0503G, loss=0.0946] \n",
      "Epoch 257/300: 100%|██████████| 469/469 [00:06<00:00, 76.74batches/s, GPU_mem=0.0503G, loss=0.0942] \n",
      "Epoch 258/300: 100%|██████████| 469/469 [00:05<00:00, 79.83batches/s, GPU_mem=0.0503G, loss=0.0937] \n",
      "Epoch 259/300: 100%|██████████| 469/469 [00:06<00:00, 76.86batches/s, GPU_mem=0.0503G, loss=0.093]  \n",
      "Epoch 260/300: 100%|██████████| 469/469 [00:06<00:00, 78.07batches/s, GPU_mem=0.0503G, loss=0.0925] \n",
      "Epoch 261/300: 100%|██████████| 469/469 [00:06<00:00, 76.47batches/s, GPU_mem=0.0503G, loss=0.0926] \n",
      "Epoch 262/300: 100%|██████████| 469/469 [00:06<00:00, 74.17batches/s, GPU_mem=0.0503G, loss=0.0921] \n",
      "Epoch 263/300: 100%|██████████| 469/469 [00:06<00:00, 76.76batches/s, GPU_mem=0.0503G, loss=0.0923] \n",
      "Epoch 264/300: 100%|██████████| 469/469 [00:06<00:00, 77.41batches/s, GPU_mem=0.0503G, loss=0.0913] \n",
      "Epoch 265/300: 100%|██████████| 469/469 [00:06<00:00, 75.41batches/s, GPU_mem=0.0503G, loss=0.0918] \n",
      "Epoch 266/300: 100%|██████████| 469/469 [00:06<00:00, 76.64batches/s, GPU_mem=0.0503G, loss=0.0906] \n",
      "Epoch 267/300: 100%|██████████| 469/469 [00:06<00:00, 77.33batches/s, GPU_mem=0.0503G, loss=0.0906] \n",
      "Epoch 268/300: 100%|██████████| 469/469 [00:05<00:00, 78.34batches/s, GPU_mem=0.0503G, loss=0.0899] \n",
      "Epoch 269/300: 100%|██████████| 469/469 [00:06<00:00, 77.17batches/s, GPU_mem=0.0503G, loss=0.09]   \n",
      "Epoch 270/300: 100%|██████████| 469/469 [00:06<00:00, 76.57batches/s, GPU_mem=0.0503G, loss=0.0899] \n",
      "Epoch 271/300: 100%|██████████| 469/469 [00:06<00:00, 75.86batches/s, GPU_mem=0.0503G, loss=0.0899] \n",
      "Epoch 272/300: 100%|██████████| 469/469 [00:06<00:00, 77.89batches/s, GPU_mem=0.0503G, loss=0.0893] \n",
      "Epoch 273/300: 100%|██████████| 469/469 [00:06<00:00, 77.14batches/s, GPU_mem=0.0503G, loss=0.0887] \n",
      "Epoch 274/300: 100%|██████████| 469/469 [00:05<00:00, 79.41batches/s, GPU_mem=0.0503G, loss=0.0882] \n",
      "Epoch 275/300: 100%|██████████| 469/469 [00:06<00:00, 76.33batches/s, GPU_mem=0.0503G, loss=0.0877] \n",
      "Epoch 276/300: 100%|██████████| 469/469 [00:06<00:00, 78.12batches/s, GPU_mem=0.0503G, loss=0.088]  \n",
      "Epoch 277/300: 100%|██████████| 469/469 [00:06<00:00, 73.46batches/s, GPU_mem=0.0503G, loss=0.0876] \n",
      "Epoch 278/300: 100%|██████████| 469/469 [00:06<00:00, 76.14batches/s, GPU_mem=0.0503G, loss=0.0867] \n",
      "Epoch 279/300: 100%|██████████| 469/469 [00:06<00:00, 77.71batches/s, GPU_mem=0.0503G, loss=0.0867] \n",
      "Epoch 280/300: 100%|██████████| 469/469 [00:06<00:00, 77.46batches/s, GPU_mem=0.0503G, loss=0.0861] \n",
      "Epoch 281/300: 100%|██████████| 469/469 [00:06<00:00, 76.25batches/s, GPU_mem=0.0503G, loss=0.0867] \n",
      "Epoch 282/300: 100%|██████████| 469/469 [00:06<00:00, 76.06batches/s, GPU_mem=0.0503G, loss=0.0854] \n",
      "Epoch 283/300: 100%|██████████| 469/469 [00:06<00:00, 77.06batches/s, GPU_mem=0.0503G, loss=0.0857] \n",
      "Epoch 284/300: 100%|██████████| 469/469 [00:06<00:00, 76.39batches/s, GPU_mem=0.0503G, loss=0.0855] \n",
      "Epoch 285/300: 100%|██████████| 469/469 [00:06<00:00, 77.35batches/s, GPU_mem=0.0503G, loss=0.0856] \n",
      "Epoch 286/300: 100%|██████████| 469/469 [00:06<00:00, 76.45batches/s, GPU_mem=0.0503G, loss=0.0846] \n",
      "Epoch 287/300: 100%|██████████| 469/469 [00:06<00:00, 76.70batches/s, GPU_mem=0.0503G, loss=0.0848] \n",
      "Epoch 288/300: 100%|██████████| 469/469 [00:06<00:00, 77.60batches/s, GPU_mem=0.0503G, loss=0.0846] \n",
      "Epoch 289/300: 100%|██████████| 469/469 [00:06<00:00, 76.83batches/s, GPU_mem=0.0503G, loss=0.0835] \n",
      "Epoch 290/300: 100%|██████████| 469/469 [00:06<00:00, 77.31batches/s, GPU_mem=0.0503G, loss=0.0842] \n",
      "Epoch 291/300: 100%|██████████| 469/469 [00:06<00:00, 77.25batches/s, GPU_mem=0.0503G, loss=0.0837] \n",
      "Epoch 292/300: 100%|██████████| 469/469 [00:06<00:00, 77.19batches/s, GPU_mem=0.0503G, loss=0.0835] \n",
      "Epoch 293/300: 100%|██████████| 469/469 [00:05<00:00, 78.93batches/s, GPU_mem=0.0503G, loss=0.0832] \n",
      "Epoch 294/300: 100%|██████████| 469/469 [00:06<00:00, 77.03batches/s, GPU_mem=0.0503G, loss=0.0829] \n",
      "Epoch 295/300: 100%|██████████| 469/469 [00:06<00:00, 76.54batches/s, GPU_mem=0.0503G, loss=0.0823] \n",
      "Epoch 296/300: 100%|██████████| 469/469 [00:06<00:00, 77.46batches/s, GPU_mem=0.0503G, loss=0.082]  \n",
      "Epoch 297/300: 100%|██████████| 469/469 [00:06<00:00, 74.54batches/s, GPU_mem=0.0503G, loss=0.0814] \n",
      "Epoch 298/300: 100%|██████████| 469/469 [00:06<00:00, 77.29batches/s, GPU_mem=0.0503G, loss=0.082]  \n",
      "Epoch 299/300: 100%|██████████| 469/469 [00:06<00:00, 77.12batches/s, GPU_mem=0.0503G, loss=0.082]  \n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "for epoch in range(epochs):\n",
    "    train_model.train()\n",
    "    mloss = torch.zeros(1, device=device)  # mean_loss\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch}/{epochs}', unit='batches')\n",
    "\n",
    "    for i, (imgs, labels) in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        preds = train_model(imgs)\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        mloss = (mloss * i + loss) / (i + 1)\n",
    "        mem = f'{torch.cuda.memory_reserved() / 1e9 if torch.cuda.is_available() else 0:.3g}G'  # GPU_mem\n",
    "        pbar.set_postfix(loss=mloss.item(), GPU_mem=mem)\n",
    "\n",
    "    ckpt = {  # checkpoint\n",
    "        'epoch': epoch,\n",
    "        'model': deepcopy(train_model).half(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(ckpt, 'LeNet5.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T17:22:18.175253Z",
     "end_time": "2023-04-16T17:51:36.330129Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "LeNet5(\n  (backbone): Sequential(\n    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n    (1): Tanh()\n    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (3): Tanh()\n    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n    (5): Tanh()\n    (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (7): Tanh()\n    (8): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n    (9): Tanh()\n    (10): Flatten(start_dim=1, end_dim=-1)\n    (11): Linear(in_features=120, out_features=84, bias=True)\n    (12): Tanh()\n    (13): Linear(in_features=84, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load('LeNet5.pt')\n",
    "test_model = ckpt['model'].to(device).float()\n",
    "test_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T17:51:36.330630Z",
     "end_time": "2023-04-16T17:51:36.384908Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='MNIST',\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=test_transform,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=128,\n",
    "    num_workers=4,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T17:51:36.353605Z",
     "end_time": "2023-04-16T17:51:36.400618Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 79/79 [00:02<00:00, 30.16batches/s]\n"
     ]
    }
   ],
   "source": [
    "correct = torch.zeros(1, device=device)\n",
    "total = torch.zeros(1, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc='Test', unit='batches')\n",
    "\n",
    "    for i, (imgs, labels) in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        preds = test_model(imgs)\n",
    "        preds = torch.argmax(nn.Softmax(dim=1)(preds), dim=1)  # 将预测结果经softmax后取最大值的序号为预测标签\n",
    "\n",
    "        total += torch.tensor(labels.size(0))\n",
    "        correct += (preds == labels).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T17:51:36.384908Z",
     "end_time": "2023-04-16T17:51:39.110145Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0.971"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = round((correct / total).item(), 3)\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T17:51:39.110145Z",
     "end_time": "2023-04-16T17:51:39.125790Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
